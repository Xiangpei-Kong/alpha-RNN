{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "KerasLayer.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfrdixon/alpha-RNN/blob/master/KerasLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmsnQfHWWlX-",
        "colab_type": "code",
        "outputId": "40e253b1-1b04-470e-a4a3-e79c648e990a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Jan 14 23:15:31 2020\n",
        "\n",
        "@author: macbookpro\n",
        "\"\"\"\n",
        " \n",
        "\n",
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import random\n",
        "import os# Generate switching data set\n",
        "import random\n",
        "\n",
        "\n",
        "# Imports for alpha_rnns \n",
        "from IPython import display\n",
        "import tensorflow.compat.v1 as tf   \n",
        "tf.disable_v2_behavior()\n",
        "# Imports for stats\n",
        "from keras.layers import Dense, Input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "from keras.layers import Layer\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l1,l2\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from keras import layers\n",
        "#from alphaRNN import *\n",
        "from keras import *\n",
        "from keras.legacy import interfaces\n",
        "# To make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot figures\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)\n",
        "    \n",
        "def generate_vol_sample(length, sigma_0, n_steps, step_size, p, eps=0.01, shift=0):\n",
        "    sigma = np.array([0]*length, dtype='float64')\n",
        "    sigma[0]=sigma_0\n",
        "    mu = np.array([0]*length, dtype='float64')\n",
        "    phi = np.array([0]*length*p, dtype='float64').reshape(length,p)\n",
        "    #phi2 = np.array([0]*length, dtype='float64')\n",
        "    step_length=100 #np.int(np.floor(np.float(length)/(2.0*n_steps)))\n",
        "    \n",
        "    for i in range(2*n_steps):\n",
        "      #mu[i*step_length:((i*step_length)+1)]=step_size #*(-1)**i\n",
        "      mu[i*step_length:((i+1)*step_length)]= step_size*(-1)**i\n",
        "      if i%2==0:  \n",
        "        phi[i*step_length:((i+1)*step_length),:]= 0.02\n",
        "        #phi2[i*step_length:((i+1)*step_length)]=1.0\n",
        "      else:\n",
        "        phi[i*step_length:((i+1)*step_length),:]=0.01\n",
        "        #phi2[i*step_length:((i+1)*step_length)]=0.5\n",
        "    for i in range(p, length):\n",
        "        sigma[i]= mu[i-1] + np.random.normal(0,eps)\n",
        "        for j in range(p):\n",
        "          sigma[i]+=phi[i-1,j]*sigma[i-j]  \n",
        "        \n",
        "    return (sigma+shift)\n",
        "\n",
        "p = 30 # the number of lags (in both the data and the models)\n",
        "vols=generate_vol_sample(2000, 0.25, 15, 0.1, p, 1e-4, 0.13)[p:]\n",
        "\n",
        "df = pd.DataFrame(vols, columns=['vol'])\n",
        "\n",
        "use_features = ['vol'] \n",
        "target = 'vol'\n",
        "n_steps = 10 # number of lags to include in the model\n",
        "\n",
        "train_weight = 0.8\n",
        "split = int(len(df)*train_weight)\n",
        "\n",
        "df_train = df[use_features].iloc[:split]\n",
        "print(df_train)\n",
        "df_test = df[use_features].iloc[split:]\n",
        "\n",
        "def get_lagged_features(value, n_steps):\n",
        "    lag_list = []\n",
        "    for lag in range(n_steps, 0, -1):\n",
        "        lag_list.append(value.shift(lag))\n",
        "    return pd.concat(lag_list, axis=1)\n",
        "\n",
        "x_train_list = []\n",
        "for use_feature in use_features:\n",
        "    x_train_reg = get_lagged_features(df_train, n_steps).dropna()\n",
        "    x_train_list.append(x_train_reg)\n",
        "#x_train_reg = pd.concat(x_train_list, axis=1)\n",
        "\n",
        "col_ords = []\n",
        "for i in range(n_steps):\n",
        "    for j in range(len(use_features)):\n",
        "        col_ords.append(i + j * n_steps)\n",
        "\n",
        "#x_train_reg = x_train_reg.iloc[:, col_ords]\n",
        "#y_train_reg = df_train.loc[x_train_reg.index, [target]].values\n",
        "#x_train_reg = np.reshape(x_train_reg.values, (x_train_reg.shape[0], np.int(x_train_reg.shape[1] / len(use_features)), len(use_features)))\n",
        "#y_train_reg = np.reshape(y_train_reg, (y_train_reg.shape[0], 1, 1))\n",
        "\n",
        "x_test_list = []\n",
        "for use_feature in use_features:\n",
        "    x_test_reg = get_lagged_features(df_test, n_steps).dropna()\n",
        "    x_test_list.append(x_test_reg)\n",
        "#x_test_reg = pd.concat(x_test_list, axis=1)\n",
        "\n",
        "#x_test_reg = x_test_reg.iloc[:, col_ords]\n",
        "#y_test_reg = df_test.loc[x_test_reg.index, [target]].values\n",
        "#x_test_reg = np.reshape(x_test_reg.values, (x_test_reg.shape[0], np.int(x_test_reg.shape[1]/len(use_features)), len(use_features)))\n",
        "\n",
        "#y_test_reg = np.reshape(y_test_reg, (y_test_reg.shape[0], 1, 1))\n",
        "\n",
        "#train_batch_size = y_train_reg.shape[0]\n",
        "#test_batch_size = y_test_reg.shape[0]    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           vol\n",
            "0     0.231685\n",
            "1     0.233905\n",
            "2     0.236207\n",
            "3     0.238376\n",
            "4     0.240477\n",
            "...        ...\n",
            "1571  0.149595\n",
            "1572  0.152918\n",
            "1573  0.156165\n",
            "1574  0.159597\n",
            "1575  0.163079\n",
            "\n",
            "[1576 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QInb-xC2MtAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY1C3s4TLSW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlphaRNNCell(Layer):\n",
        "    \"\"\"Cell class for AlphaRNN.\n",
        "    # Arguments\n",
        "        units: Positive integer, dimensionality of the output space.\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            Default: hyperbolic tangent (`tanh`).\n",
        "            If you pass `None`, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
        "            used for the linear transformation of the inputs\n",
        "            (see [initializers](../initializers.md)).\n",
        "        recurrent_initializer: Initializer for the `recurrent_kernel`\n",
        "            weights matrix,\n",
        "            used for the linear transformation of the recurrent state\n",
        "            (see [initializers](../initializers.md)).\n",
        "        bias_initializer: Initializer for the bias vector\n",
        "            (see [initializers](../initializers.md)).\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        recurrent_regularizer: Regularizer function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        bias_regularizer: Regularizer function applied to the bias vector\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        kernel_constraint: Constraint function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        recurrent_constraint: Constraint function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        bias_constraint: Constraint function applied to the bias vector\n",
        "            (see [constraints](../constraints.md)).\n",
        "        dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the inputs.\n",
        "        recurrent_dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the recurrent state.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units,\n",
        "                 activation='tanh',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 recurrent_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 recurrent_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 dropout=0.,\n",
        "                 recurrent_dropout=0.,\n",
        "                 **kwargs):\n",
        "        super(AlphaRNNCell, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.recurrent_constraint = constraints.get(recurrent_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        self.dropout = min(1., max(0., dropout))\n",
        "        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n",
        "        self.state_size = self.units\n",
        "        self.output_size = self.units\n",
        "        self._dropout_mask = None\n",
        "        self._recurrent_dropout_mask = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                      name='kernel',\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, self.units),\n",
        "            name='recurrent_kernel',\n",
        "            initializer=self.recurrent_initializer,\n",
        "            regularizer=self.recurrent_regularizer,\n",
        "            constraint=self.recurrent_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.units,),\n",
        "                                        name='bias',\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        \n",
        "        self.alpha = self.add_weight(shape=(1,),\n",
        "                                        name='alpha',\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states, training=None):\n",
        "        prev_output = states[0]\n",
        "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
        "            self._dropout_mask = _generate_dropout_mask(\n",
        "                K.ones_like(inputs),\n",
        "                self.dropout,\n",
        "                training=training)\n",
        "        if (0 < self.recurrent_dropout < 1 and\n",
        "                self._recurrent_dropout_mask is None):\n",
        "            self._recurrent_dropout_mask = _generate_dropout_mask(\n",
        "                K.ones_like(prev_output),\n",
        "                self.recurrent_dropout,\n",
        "                training=training)\n",
        "\n",
        "        dp_mask = self._dropout_mask\n",
        "        rec_dp_mask = self._recurrent_dropout_mask\n",
        "\n",
        "        if dp_mask is not None:\n",
        "            h = K.dot(inputs * dp_mask, self.kernel)\n",
        "        else:\n",
        "            h = K.dot(inputs, self.kernel)\n",
        "        if self.bias is not None:\n",
        "            h = K.bias_add(h, self.bias)\n",
        "\n",
        "        if rec_dp_mask is not None:\n",
        "            prev_output *= rec_dp_mask\n",
        "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        output = K.tanh(self.alpha)* output + 1-K.tanh(self.alpha)* prev_output\n",
        "        # Properly set learning phase on output tensor.\n",
        "        if 0 < self.dropout + self.recurrent_dropout:\n",
        "            if training is None:\n",
        "                output._uses_learning_phase = True\n",
        "        return output, [output]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'kernel_initializer':\n",
        "                      initializers.serialize(self.kernel_initializer),\n",
        "                  'recurrent_initializer':\n",
        "                      initializers.serialize(self.recurrent_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer':\n",
        "                      regularizers.serialize(self.kernel_regularizer),\n",
        "                  'recurrent_regularizer':\n",
        "                      regularizers.serialize(self.recurrent_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'recurrent_constraint':\n",
        "                      constraints.serialize(self.recurrent_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'dropout': self.dropout,\n",
        "                  'recurrent_dropout': self.recurrent_dropout}\n",
        "        base_config = super(AlphaRNNCell, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class AlphaRNN(keras.layers.RNN):\n",
        "    \"\"\"Fully-connected AlphaRNN where the output is to be fed back to input.\n",
        "    # Arguments\n",
        "        units: Positive integer, dimensionality of the output space.\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            Default: hyperbolic tangent (`tanh`).\n",
        "            If you pass `None`, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
        "            used for the linear transformation of the inputs\n",
        "            (see [initializers](../initializers.md)).\n",
        "        recurrent_initializer: Initializer for the `recurrent_kernel`\n",
        "            weights matrix,\n",
        "            used for the linear transformation of the recurrent state\n",
        "            (see [initializers](../initializers.md)).\n",
        "        bias_initializer: Initializer for the bias vector\n",
        "            (see [initializers](../initializers.md)).\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        recurrent_regularizer: Regularizer function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        bias_regularizer: Regularizer function applied to the bias vector\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        activity_regularizer: Regularizer function applied to\n",
        "            the output of the layer (its \"activation\").\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        kernel_constraint: Constraint function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        recurrent_constraint: Constraint function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        bias_constraint: Constraint function applied to the bias vector\n",
        "            (see [constraints](../constraints.md)).\n",
        "        dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the inputs.\n",
        "        recurrent_dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the recurrent state.\n",
        "        return_sequences: Boolean. Whether to return the last output\n",
        "            in the output sequence, or the full sequence.\n",
        "        return_state: Boolean. Whether to return the last state\n",
        "            in addition to the output.\n",
        "        go_backwards: Boolean (default False).\n",
        "            If True, process the input sequence backwards and return the\n",
        "            reversed sequence.\n",
        "        stateful: Boolean (default False). If True, the last state\n",
        "            for each sample at index i in a batch will be used as initial\n",
        "            state for the sample of index i in the following batch.\n",
        "        unroll: Boolean (default False).\n",
        "            If True, the network will be unrolled,\n",
        "            else a symbolic loop will be used.\n",
        "            Unrolling can speed-up a RNN,\n",
        "            although it tends to be more memory-intensive.\n",
        "            Unrolling is only suitable for short sequences.\n",
        "    \"\"\"\n",
        "\n",
        "    @interfaces.legacy_recurrent_support\n",
        "    def __init__(self, units,\n",
        "                 activation='tanh',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 recurrent_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 recurrent_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 dropout=0.,\n",
        "                 recurrent_dropout=0.,\n",
        "                 return_sequences=False,\n",
        "                 return_state=False,\n",
        "                 go_backwards=False,\n",
        "                 stateful=False,\n",
        "                 unroll=False,\n",
        "                 **kwargs):\n",
        "        if 'implementation' in kwargs:\n",
        "            kwargs.pop('implementation')\n",
        "            warnings.warn('The `implementation` argument '\n",
        "                          'in `SimpleRNN` has been deprecated. '\n",
        "                          'Please remove it from your layer call.')\n",
        "        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n",
        "            warnings.warn(\n",
        "                'RNN dropout is no longer supported with the Theano backend '\n",
        "                'due to technical limitations. '\n",
        "                'You can either set `dropout` and `recurrent_dropout` to 0, '\n",
        "                'or use the TensorFlow backend.')\n",
        "            dropout = 0.\n",
        "            recurrent_dropout = 0.\n",
        "\n",
        "        cell = AlphaRNNCell(units,\n",
        "                             activation=activation,\n",
        "                             use_bias=use_bias,\n",
        "                             kernel_initializer=kernel_initializer,\n",
        "                             recurrent_initializer=recurrent_initializer,\n",
        "                             bias_initializer=bias_initializer,\n",
        "                             kernel_regularizer=kernel_regularizer,\n",
        "                             recurrent_regularizer=recurrent_regularizer,\n",
        "                             bias_regularizer=bias_regularizer,\n",
        "                             kernel_constraint=kernel_constraint,\n",
        "                             recurrent_constraint=recurrent_constraint,\n",
        "                             bias_constraint=bias_constraint,\n",
        "                             dropout=dropout,\n",
        "                             recurrent_dropout=recurrent_dropout)\n",
        "        super(AlphaRNN, self).__init__(cell,\n",
        "                                        return_sequences=return_sequences,\n",
        "                                        return_state=return_state,\n",
        "                                        go_backwards=go_backwards,\n",
        "                                        stateful=stateful,\n",
        "                                        unroll=unroll,\n",
        "                                        **kwargs)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "    def call(self, inputs, mask=None, training=None, initial_state=None):\n",
        "        self.cell._dropout_mask = None\n",
        "        self.cell._recurrent_dropout_mask = None\n",
        "        return super(AlphaRNN, self).call(inputs,\n",
        "                                           mask=mask,\n",
        "                                           training=training,\n",
        "                                           initial_state=initial_state)\n",
        "\n",
        "    @property\n",
        "    def units(self):\n",
        "        return self.cell.units\n",
        "\n",
        "    @property\n",
        "    def activation(self):\n",
        "        return self.cell.activation\n",
        "\n",
        "    @property\n",
        "    def use_bias(self):\n",
        "        return self.cell.use_bias\n",
        "\n",
        "    @property\n",
        "    def kernel_initializer(self):\n",
        "        return self.cell.kernel_initializer\n",
        "\n",
        "    @property\n",
        "    def recurrent_initializer(self):\n",
        "        return self.cell.recurrent_initializer\n",
        "\n",
        "    @property\n",
        "    def bias_initializer(self):\n",
        "        return self.cell.bias_initializer\n",
        "\n",
        "    @property\n",
        "    def kernel_regularizer(self):\n",
        "        return self.cell.kernel_regularizer\n",
        "\n",
        "    @property\n",
        "    def recurrent_regularizer(self):\n",
        "        return self.cell.recurrent_regularizer\n",
        "\n",
        "    @property\n",
        "    def bias_regularizer(self):\n",
        "        return self.cell.bias_regularizer\n",
        "\n",
        "    @property\n",
        "    def kernel_constraint(self):\n",
        "        return self.cell.kernel_constraint\n",
        "\n",
        "    @property\n",
        "    def recurrent_constraint(self):\n",
        "        return self.cell.recurrent_constraint\n",
        "\n",
        "    @property\n",
        "    def bias_constraint(self):\n",
        "        return self.cell.bias_constraint\n",
        "\n",
        "    @property\n",
        "    def dropout(self):\n",
        "        return self.cell.dropout\n",
        "\n",
        "    @property\n",
        "    def recurrent_dropout(self):\n",
        "        return self.cell.recurrent_dropout\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'kernel_initializer':\n",
        "                      initializers.serialize(self.kernel_initializer),\n",
        "                  'recurrent_initializer':\n",
        "                      initializers.serialize(self.recurrent_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer':\n",
        "                      regularizers.serialize(self.kernel_regularizer),\n",
        "                  'recurrent_regularizer':\n",
        "                      regularizers.serialize(self.recurrent_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'activity_regularizer':\n",
        "                      regularizers.serialize(self.activity_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'recurrent_constraint':\n",
        "                      constraints.serialize(self.recurrent_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'dropout': self.dropout,\n",
        "                  'recurrent_dropout': self.recurrent_dropout}\n",
        "        base_config = super(AlphaRNN, self).get_config()\n",
        "        del base_config['cell']\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        if 'implementation' in config:\n",
        "            config.pop('implementation')\n",
        "        return cls(**config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdobsJiulG0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlphatRNNCell(Layer):\n",
        "    \"\"\"Cell class for the AlphatRNN layer.\n",
        "    # Arguments\n",
        "        units: Positive integer, dimensionality of the output space.\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            Default: hyperbolic tangent (`tanh`).\n",
        "            If you pass `None`, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        recurrent_activation: Activation function to use\n",
        "            for the recurrent step\n",
        "            (see [activations](../activations.md)).\n",
        "            Default: sigmoid (`sigmoid`).\n",
        "            If you pass `None`, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
        "            used for the linear transformation of the inputs\n",
        "            (see [initializers](../initializers.md)).\n",
        "        recurrent_initializer: Initializer for the `recurrent_kernel`\n",
        "            weights matrix,\n",
        "            used for the linear transformation of the recurrent state\n",
        "            (see [initializers](../initializers.md)).\n",
        "        bias_initializer: Initializer for the bias vector\n",
        "            (see [initializers](../initializers.md)).\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        recurrent_regularizer: Regularizer function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        bias_regularizer: Regularizer function applied to the bias vector\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        kernel_constraint: Constraint function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        recurrent_constraint: Constraint function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        bias_constraint: Constraint function applied to the bias vector\n",
        "            (see [constraints](../constraints.md)).\n",
        "        dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the inputs.\n",
        "        recurrent_dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the recurrent state.\n",
        "        implementation: Implementation mode, either 1 or 2.\n",
        "            Mode 1 will structure its operations as a larger number of\n",
        "            smaller dot products and additions, whereas mode 2 will\n",
        "            batch them into fewer, larger operations. These modes will\n",
        "            have different performance profiles on different hardware and\n",
        "            for different applications.\n",
        "        reset_after: GRU convention (whether to apply reset gate after or\n",
        "            before matrix multiplication). False = \"before\" (default),\n",
        "            True = \"after\" (CuDNN compatible).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units,\n",
        "                 activation='tanh',\n",
        "                 recurrent_activation='sigmoid',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 recurrent_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 recurrent_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 dropout=0.,\n",
        "                 recurrent_dropout=0.,\n",
        "                 implementation=2,\n",
        "                 **kwargs):\n",
        "        super(AlphatRNNCell, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = activations.get(activation)\n",
        "        self.recurrent_activation = activations.get(recurrent_activation)\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.recurrent_constraint = constraints.get(recurrent_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        self.dropout = min(1., max(0., dropout))\n",
        "        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n",
        "        self.implementation = implementation\n",
        "        self.state_size = self.units\n",
        "        self.output_size = self.units\n",
        "        self._dropout_mask = None\n",
        "        self._recurrent_dropout_mask = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[-1]\n",
        "\n",
        "        if isinstance(self.recurrent_initializer, initializers.Identity):\n",
        "            def recurrent_identity(shape, gain=1., dtype=None):\n",
        "                del dtype\n",
        "                return gain * np.concatenate(\n",
        "                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n",
        "\n",
        "            self.recurrent_initializer = recurrent_identity\n",
        "\n",
        "        self.kernel = self.add_weight(shape=(input_dim, self.units * 2),\n",
        "                                      name='kernel',\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, self.units * 2),\n",
        "            name='recurrent_kernel',\n",
        "            initializer=self.recurrent_initializer,\n",
        "            regularizer=self.recurrent_regularizer,\n",
        "            constraint=self.recurrent_constraint)\n",
        "\n",
        "        if self.use_bias:\n",
        "            bias_shape = (2, 2 * self.units)\n",
        "            self.bias = self.add_weight(shape=bias_shape,\n",
        "                                        name='bias',\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "            \n",
        "            self.input_bias = K.flatten(self.bias[0])\n",
        "            self.recurrent_bias = K.flatten(self.bias[1])\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        # alpha\n",
        "        self.kernel_alpha = self.kernel[:, :self.units]\n",
        "        self.recurrent_kernel_alpha = self.recurrent_kernel[:, :self.units]\n",
        "        # recurrnce\n",
        "        self.kernel_h = self.kernel[:, self.units:]\n",
        "        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units:]\n",
        "\n",
        "        if self.use_bias:\n",
        "            # bias for inputs\n",
        "            self.input_bias_alpha = self.input_bias[:self.units]\n",
        "            self.input_bias_h = self.input_bias[self.units:]\n",
        "            # bias for hidden state - just for compatibility with CuDNN\n",
        "            \n",
        "            self.recurrent_bias_alpha = self.recurrent_bias[:self.units]    \n",
        "            self.recurrent_bias_h = self.recurrent_bias[self.units:]\n",
        "        else:\n",
        "            self.input_bias_alpha = None\n",
        "            self.input_bias_h = None\n",
        "            \n",
        "            self.recurrent_bias_alpha = None\n",
        "            self.recurrent_bias_h = None\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states, training=None):\n",
        "        h_tm1 = states[0]  # previous memory\n",
        "\n",
        "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
        "            self._dropout_mask = _generate_dropout_mask(\n",
        "                K.ones_like(inputs),\n",
        "                self.dropout,\n",
        "                training=training,\n",
        "                count=2)\n",
        "        if (0 < self.recurrent_dropout < 1 and\n",
        "                self._recurrent_dropout_mask is None):\n",
        "            self._recurrent_dropout_mask = _generate_dropout_mask(\n",
        "                K.ones_like(h_tm1),\n",
        "                self.recurrent_dropout,\n",
        "                training=training,\n",
        "                count=2)\n",
        "\n",
        "        # dropout matrices for input units\n",
        "        dp_mask = self._dropout_mask\n",
        "        # dropout matrices for recurrent units\n",
        "        rec_dp_mask = self._recurrent_dropout_mask\n",
        "\n",
        "        if self.implementation == 1:\n",
        "            if 0. < self.dropout < 1.:\n",
        "                inputs_alpha = inputs * dp_mask[0]\n",
        "                inputs_h = inputs * dp_mask[1]\n",
        "            else:\n",
        "                inputs_alpha = input\n",
        "                inputs_h = inputs\n",
        "\n",
        "            x_alpha = K.dot(inputs_alpha, self.kernel_alpha)\n",
        "            x_h = K.dot(inputs_h, self.kernel_h)\n",
        "            if self.use_bias:\n",
        "                x_alpha = K.bias_add(x_alpha, self.input_bias_alpha)\n",
        "                x_h = K.bias_add(x_h, self.input_bias_h)\n",
        "\n",
        "            if 0. < self.recurrent_dropout < 1.:\n",
        "                h_tm1_alpha = h_tm1 * rec_dp_mask[0]\n",
        "                h_tm1_h = h_tm1 * rec_dp_mask[1]\n",
        "            else:\n",
        "                h_tm1_alpha = h_tm1\n",
        "                h_tm1_h = h_tm1\n",
        "\n",
        "            recurrent_alpha = K.dot(h_tm1_alpha, self.recurrent_kernel_alpha)\n",
        "           \n",
        "            if self.use_bias:\n",
        "                recurrent_alpha = K.bias_add(recurrent_alpha, self.recurrent_bias_alpha)\n",
        "\n",
        "            alpha = self.recurrent_activation(x_alpha + recurrent_alpha)\n",
        "            \n",
        "           \n",
        "            recurrent_h = K.dot(h_tm1_h, self.recurrent_kernel_h)\n",
        "            if self.use_bias:\n",
        "                recurrent_h = K.bias_add(recurrent_h, self.recurrent_bias_h)\n",
        "            \n",
        "            hh = self.activation(x_h + recurrent_h)\n",
        "        else:\n",
        "            if 0. < self.dropout < 1.:\n",
        "                inputs *= dp_mask[0]\n",
        "\n",
        "            # inputs projected by all gate matrices at once\n",
        "            matrix_x = K.dot(inputs, self.kernel)\n",
        "            if self.use_bias:\n",
        "                # biases: bias_z_i, bias_r_i, bias_h_i\n",
        "                matrix_x = K.bias_add(matrix_x, self.input_bias)\n",
        "            x_alpha = matrix_x[:, :self.units]\n",
        "            x_h = matrix_x[:, self.units: 2 * self.units]\n",
        "            \n",
        "            if 0. < self.recurrent_dropout < 1.:\n",
        "                h_tm1 *= rec_dp_mask[0]\n",
        "\n",
        "            \n",
        "            matrix_inner = K.dot(h_tm1, self.recurrent_kernel)\n",
        "            if self.use_bias:\n",
        "                  matrix_inner = K.bias_add(matrix_inner, self.recurrent_bias)\n",
        "            \n",
        "            recurrent_alpha = matrix_inner[:, :self.units] \n",
        "            alpha = self.recurrent_activation(x_alpha + recurrent_alpha)\n",
        "            \n",
        "            recurrent_h = matrix_inner[:, self.units: 2 * self.units]  \n",
        "            hh = self.activation(x_h + recurrent_h)\n",
        "\n",
        "        # previous and candidate state mixed by update gate\n",
        "        h = alpha * h_tm1 + (1 - alpha) * hh\n",
        "\n",
        "        if 0 < self.dropout + self.recurrent_dropout:\n",
        "            if training is None:\n",
        "                h._uses_learning_phase = True\n",
        "\n",
        "        return h, [h]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'recurrent_activation':\n",
        "                      activations.serialize(self.recurrent_activation),\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'kernel_initializer':\n",
        "                      initializers.serialize(self.kernel_initializer),\n",
        "                  'recurrent_initializer':\n",
        "                      initializers.serialize(self.recurrent_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer':\n",
        "                      regularizers.serialize(self.kernel_regularizer),\n",
        "                  'recurrent_regularizer':\n",
        "                      regularizers.serialize(self.recurrent_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'recurrent_constraint':\n",
        "                      constraints.serialize(self.recurrent_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'dropout': self.dropout,\n",
        "                  'recurrent_dropout': self.recurrent_dropout,\n",
        "                  'implementation': self.implementation}\n",
        "        base_config = super(AlphatRNNCell, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class AlphatRNN(keras.layers.RNN):\n",
        "    \"\"\"Alpha_t RNN\n",
        "    There are two variants. The default one is based on 1406.1078v3 and\n",
        "    has reset gate applied to hidden state before matrix multiplication. The\n",
        "    other one is based on original 1406.1078v1 and has the order reversed.\n",
        "    The second variant is compatible with CuDNNGRU (GPU-only) and allows\n",
        "    inference on CPU. Thus it has separate biases for `kernel` and\n",
        "    `recurrent_kernel`. Use `'reset_after'=True` and\n",
        "    `recurrent_activation='sigmoid'`.\n",
        "    # Arguments\n",
        "        units: Positive integer, dimensionality of the output space.\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            Default: hyperbolic tangent (`tanh`).\n",
        "            If you pass `None`, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        recurrent_activation: Activation function to use\n",
        "            for the recurrent step\n",
        "            (see [activations](../activations.md)).\n",
        "            Default: sigmoid (`sigmoid`).\n",
        "            If you pass `None`, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
        "            used for the linear transformation of the inputs\n",
        "            (see [initializers](../initializers.md)).\n",
        "        recurrent_initializer: Initializer for the `recurrent_kernel`\n",
        "            weights matrix,\n",
        "            used for the linear transformation of the recurrent state\n",
        "            (see [initializers](../initializers.md)).\n",
        "        bias_initializer: Initializer for the bias vector\n",
        "            (see [initializers](../initializers.md)).\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        recurrent_regularizer: Regularizer function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        bias_regularizer: Regularizer function applied to the bias vector\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        activity_regularizer: Regularizer function applied to\n",
        "            the output of the layer (its \"activation\").\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        kernel_constraint: Constraint function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        recurrent_constraint: Constraint function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        bias_constraint: Constraint function applied to the bias vector\n",
        "            (see [constraints](../constraints.md)).\n",
        "        dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the inputs.\n",
        "        recurrent_dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the recurrent state.\n",
        "        implementation: Implementation mode, either 1 or 2.\n",
        "            Mode 1 will structure its operations as a larger number of\n",
        "            smaller dot products and additions, whereas mode 2 will\n",
        "            batch them into fewer, larger operations. These modes will\n",
        "            have different performance profiles on different hardware and\n",
        "            for different applications.\n",
        "        return_sequences: Boolean. Whether to return the last output\n",
        "            in the output sequence, or the full sequence.\n",
        "        return_state: Boolean. Whether to return the last state\n",
        "            in addition to the output.\n",
        "        go_backwards: Boolean (default False).\n",
        "            If True, process the input sequence backwards and return the\n",
        "            reversed sequence.\n",
        "        stateful: Boolean (default False). If True, the last state\n",
        "            for each sample at index i in a batch will be used as initial\n",
        "            state for the sample of index i in the following batch.\n",
        "        unroll: Boolean (default False).\n",
        "            If True, the network will be unrolled,\n",
        "            else a symbolic loop will be used.\n",
        "            Unrolling can speed-up a RNN,\n",
        "            although it tends to be more memory-intensive.\n",
        "            Unrolling is only suitable for short sequences.\n",
        "        \n",
        "    # References\n",
        "        - [Learning Phrase Representations using RNN Encoder-Decoder for\n",
        "           Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n",
        "        - [On the Properties of Neural Machine Translation:\n",
        "           Encoder-Decoder Approaches](https://arxiv.org/abs/1409.1259)\n",
        "        - [Empirical Evaluation of Gated Recurrent Neural Networks on\n",
        "           Sequence Modeling](https://arxiv.org/abs/1412.3555v1)\n",
        "        - [A Theoretically Grounded Application of Dropout in\n",
        "           Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n",
        "    \"\"\"\n",
        "\n",
        "    @interfaces.legacy_recurrent_support\n",
        "    def __init__(self, units,\n",
        "                 activation='tanh',\n",
        "                 recurrent_activation='sigmoid',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer='orthogonal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 recurrent_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 recurrent_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 dropout=0.,\n",
        "                 recurrent_dropout=0.,\n",
        "                 implementation=2,\n",
        "                 return_sequences=False,\n",
        "                 return_state=False,\n",
        "                 go_backwards=False,\n",
        "                 stateful=False,\n",
        "                 unroll=False,\n",
        "                 **kwargs):\n",
        "        if implementation == 0:\n",
        "            warnings.warn('`implementation=0` has been deprecated, '\n",
        "                          'and now defaults to `implementation=1`.'\n",
        "                          'Please update your layer call.')\n",
        "        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n",
        "            warnings.warn(\n",
        "                'RNN dropout is no longer supported with the Theano backend '\n",
        "                'due to technical limitations. '\n",
        "                'You can either set `dropout` and `recurrent_dropout` to 0, '\n",
        "                'or use the TensorFlow backend.')\n",
        "            dropout = 0.\n",
        "            recurrent_dropout = 0.\n",
        "\n",
        "        cell = AlphatRNNCell(units,\n",
        "                       activation=activation,\n",
        "                       recurrent_activation=recurrent_activation,\n",
        "                       use_bias=use_bias,\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       recurrent_initializer=recurrent_initializer,\n",
        "                       bias_initializer=bias_initializer,\n",
        "                       kernel_regularizer=kernel_regularizer,\n",
        "                       recurrent_regularizer=recurrent_regularizer,\n",
        "                       bias_regularizer=bias_regularizer,\n",
        "                       kernel_constraint=kernel_constraint,\n",
        "                       recurrent_constraint=recurrent_constraint,\n",
        "                       bias_constraint=bias_constraint,\n",
        "                       dropout=dropout,\n",
        "                       recurrent_dropout=recurrent_dropout,\n",
        "                       implementation=implementation)             \n",
        "        super(AlphatRNN, self).__init__(cell,\n",
        "                                  return_sequences=return_sequences,\n",
        "                                  return_state=return_state,\n",
        "                                  go_backwards=go_backwards,\n",
        "                                  stateful=stateful,\n",
        "                                  unroll=unroll,\n",
        "                                  **kwargs)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "    def call(self, inputs, mask=None, training=None, initial_state=None):\n",
        "        self.cell._dropout_mask = None\n",
        "        self.cell._recurrent_dropout_mask = None\n",
        "        return super(AlphatRNN, self).call(inputs,\n",
        "                                     mask=mask,\n",
        "                                     training=training,\n",
        "                                     initial_state=initial_state)\n",
        "\n",
        "    @property\n",
        "    def units(self):\n",
        "        return self.cell.units\n",
        "\n",
        "    @property\n",
        "    def activation(self):\n",
        "        return self.cell.activation\n",
        "\n",
        "    @property\n",
        "    def recurrent_activation(self):\n",
        "        return self.cell.recurrent_activation\n",
        "\n",
        "    @property\n",
        "    def use_bias(self):\n",
        "        return self.cell.use_bias\n",
        "\n",
        "    @property\n",
        "    def kernel_initializer(self):\n",
        "        return self.cell.kernel_initializer\n",
        "\n",
        "    @property\n",
        "    def recurrent_initializer(self):\n",
        "        return self.cell.recurrent_initializer\n",
        "\n",
        "    @property\n",
        "    def bias_initializer(self):\n",
        "        return self.cell.bias_initializer\n",
        "\n",
        "    @property\n",
        "    def kernel_regularizer(self):\n",
        "        return self.cell.kernel_regularizer\n",
        "\n",
        "    @property\n",
        "    def recurrent_regularizer(self):\n",
        "        return self.cell.recurrent_regularizer\n",
        "\n",
        "    @property\n",
        "    def bias_regularizer(self):\n",
        "        return self.cell.bias_regularizer\n",
        "\n",
        "    @property\n",
        "    def kernel_constraint(self):\n",
        "        return self.cell.kernel_constraint\n",
        "\n",
        "    @property\n",
        "    def recurrent_constraint(self):\n",
        "        return self.cell.recurrent_constraint\n",
        "\n",
        "    @property\n",
        "    def bias_constraint(self):\n",
        "        return self.cell.bias_constraint\n",
        "\n",
        "    @property\n",
        "    def dropout(self):\n",
        "        return self.cell.dropout\n",
        "\n",
        "    @property\n",
        "    def recurrent_dropout(self):\n",
        "        return self.cell.recurrent_dropout\n",
        "\n",
        "    @property\n",
        "    def implementation(self):\n",
        "        return self.cell.implementation\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'recurrent_activation':\n",
        "                      activations.serialize(self.recurrent_activation),\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'kernel_initializer':\n",
        "                      initializers.serialize(self.kernel_initializer),\n",
        "                  'recurrent_initializer':\n",
        "                      initializers.serialize(self.recurrent_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer':\n",
        "                      regularizers.serialize(self.kernel_regularizer),\n",
        "                  'recurrent_regularizer':\n",
        "                      regularizers.serialize(self.recurrent_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'activity_regularizer':\n",
        "                      regularizers.serialize(self.activity_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'recurrent_constraint':\n",
        "                      constraints.serialize(self.recurrent_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'dropout': self.dropout,\n",
        "                  'recurrent_dropout': self.recurrent_dropout,\n",
        "                  'implementation': self.implementation}\n",
        "        base_config = super(AlphatRNN, self).get_config()\n",
        "        del base_config['cell']\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        if 'implementation' in config and config['implementation'] == 0:\n",
        "            config['implementation'] = 1\n",
        "        return cls(**config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Ls0KyNONY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_reg = pd.concat(x_train_list, axis=1)\n",
        "x_train_reg = x_train_reg.iloc[:, col_ords]\n",
        "y_train_reg = df_train.loc[x_train_reg.index, [target]].values\n",
        "x_train_reg = np.reshape(x_train_reg.values, (x_train_reg.shape[0], np.int(x_train_reg.shape[1] / len(use_features)), len(use_features)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSSokmMsOa1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_reg = pd.concat(x_test_list, axis=1)\n",
        "x_test_reg = x_test_reg.iloc[:, col_ords]\n",
        "y_test_reg = df_test.loc[x_test_reg.index, [target]].values\n",
        "x_test_reg = np.reshape(x_test_reg.values, (x_test_reg.shape[0], np.int(x_test_reg.shape[1]/len(use_features)), len(use_features)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ9YQuMUg0bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=1e-2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMbxTnZCUdJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae62a618-b881-40c5-da40-1eb19c0c5c0a"
      },
      "source": [
        "hidden_units=5\n",
        "l1_reg=0\n",
        "reg_model = Sequential()\n",
        "reg_model.add(AlphatRNN(hidden_units, activation='sigmoid', recurrent_activation='tanh', input_shape=(x_train_reg.shape[1], x_train_reg.shape[-1]), unroll=True))\n",
        "reg_model.add(Dense(1, kernel_initializer='normal', kernel_regularizer=l1(l1_reg)))\n",
        "#reg_model.add(Dropout(0.2))\n",
        "reg_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "reg_model.fit(x_train_reg,y_train_reg,epochs=2000, batch_size=100,callbacks=[es])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "1566/1566 [==============================] - 2s 1ms/step - loss: 0.0348\n",
            "Epoch 2/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0269\n",
            "Epoch 3/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 0.0252\n",
            "Epoch 4/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 0.0251\n",
            "Epoch 5/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 0.0250\n",
            "Epoch 6/2000\n",
            " 100/1566 [>.............................] - ETA: 0s - loss: 0.0270"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:842: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0249\n",
            "Epoch 7/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 0.0248\n",
            "Epoch 8/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0246\n",
            "Epoch 9/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0245\n",
            "Epoch 10/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0244\n",
            "Epoch 11/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0243\n",
            "Epoch 12/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 0.0242\n",
            "Epoch 13/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0241\n",
            "Epoch 14/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0240\n",
            "Epoch 15/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0239\n",
            "Epoch 16/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0239\n",
            "Epoch 17/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0238\n",
            "Epoch 18/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0237\n",
            "Epoch 19/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0236\n",
            "Epoch 20/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 0.0236\n",
            "Epoch 21/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0235\n",
            "Epoch 22/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0234\n",
            "Epoch 23/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0233\n",
            "Epoch 24/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0232\n",
            "Epoch 25/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0231\n",
            "Epoch 26/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0229\n",
            "Epoch 27/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0227\n",
            "Epoch 28/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0225\n",
            "Epoch 29/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0222\n",
            "Epoch 30/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0219\n",
            "Epoch 31/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 0.0214\n",
            "Epoch 32/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0201\n",
            "Epoch 33/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0171\n",
            "Epoch 34/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0119\n",
            "Epoch 35/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0067\n",
            "Epoch 36/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0043\n",
            "Epoch 37/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0038\n",
            "Epoch 38/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 0.0037\n",
            "Epoch 39/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0036\n",
            "Epoch 40/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 0.0035\n",
            "Epoch 41/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0035\n",
            "Epoch 42/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0035\n",
            "Epoch 43/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0034\n",
            "Epoch 44/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0034\n",
            "Epoch 45/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0034\n",
            "Epoch 46/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0033\n",
            "Epoch 47/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0034\n",
            "Epoch 48/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0033\n",
            "Epoch 49/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0031\n",
            "Epoch 50/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0031\n",
            "Epoch 51/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0031\n",
            "Epoch 52/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 0.0030\n",
            "Epoch 53/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0030\n",
            "Epoch 54/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 0.0029\n",
            "Epoch 55/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 0.0029\n",
            "Epoch 56/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0028\n",
            "Epoch 57/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 0.0028\n",
            "Epoch 58/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 0.0027\n",
            "Epoch 59/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0027\n",
            "Epoch 60/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 0.0026\n",
            "Epoch 61/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0026\n",
            "Epoch 62/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0025\n",
            "Epoch 63/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0025\n",
            "Epoch 64/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0024\n",
            "Epoch 65/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0024\n",
            "Epoch 66/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0023\n",
            "Epoch 67/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0023\n",
            "Epoch 68/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0022\n",
            "Epoch 69/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0022\n",
            "Epoch 70/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0021\n",
            "Epoch 71/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0020\n",
            "Epoch 72/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 0.0020\n",
            "Epoch 73/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0019\n",
            "Epoch 74/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0019\n",
            "Epoch 75/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0019\n",
            "Epoch 76/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 0.0018\n",
            "Epoch 77/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0017\n",
            "Epoch 78/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0017\n",
            "Epoch 79/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0017\n",
            "Epoch 80/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0016\n",
            "Epoch 81/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0015\n",
            "Epoch 82/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0015\n",
            "Epoch 83/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 0.0015\n",
            "Epoch 84/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 0.0014\n",
            "Epoch 85/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 0.0013\n",
            "Epoch 86/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 0.0013\n",
            "Epoch 87/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0013\n",
            "Epoch 88/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0012\n",
            "Epoch 89/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 0.0011\n",
            "Epoch 90/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 0.0011\n",
            "Epoch 91/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 0.0011\n",
            "Epoch 92/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 0.0010\n",
            "Epoch 93/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 9.5055e-04\n",
            "Epoch 94/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 9.2183e-04\n",
            "Epoch 95/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 8.7582e-04\n",
            "Epoch 96/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 8.7701e-04\n",
            "Epoch 97/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 8.3152e-04\n",
            "Epoch 98/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 7.9787e-04\n",
            "Epoch 99/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 7.9186e-04\n",
            "Epoch 100/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 7.6511e-04\n",
            "Epoch 101/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 7.5094e-04\n",
            "Epoch 102/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 7.4524e-04\n",
            "Epoch 103/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 7.3128e-04\n",
            "Epoch 104/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 7.3425e-04\n",
            "Epoch 105/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 7.4023e-04\n",
            "Epoch 106/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 7.2532e-04\n",
            "Epoch 107/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 7.4184e-04\n",
            "Epoch 108/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 7.3515e-04\n",
            "Epoch 109/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 7.3373e-04\n",
            "Epoch 110/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 7.4100e-04\n",
            "Epoch 111/2000\n",
            "1566/1566 [==============================] - 0s 42us/step - loss: 7.1995e-04\n",
            "Epoch 112/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.9803e-04\n",
            "Epoch 113/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 7.1646e-04\n",
            "Epoch 114/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 7.1083e-04\n",
            "Epoch 115/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.9703e-04\n",
            "Epoch 116/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.8754e-04\n",
            "Epoch 117/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.8999e-04\n",
            "Epoch 118/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 6.9098e-04\n",
            "Epoch 119/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.8792e-04\n",
            "Epoch 120/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 6.8409e-04\n",
            "Epoch 121/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.9060e-04\n",
            "Epoch 122/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.7405e-04\n",
            "Epoch 123/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.7452e-04\n",
            "Epoch 124/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.7689e-04\n",
            "Epoch 125/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 7.0398e-04\n",
            "Epoch 126/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 7.1345e-04\n",
            "Epoch 127/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.7553e-04\n",
            "Epoch 128/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.6550e-04\n",
            "Epoch 129/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 6.6315e-04\n",
            "Epoch 130/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.6178e-04\n",
            "Epoch 131/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.6689e-04\n",
            "Epoch 132/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.7060e-04\n",
            "Epoch 133/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.5795e-04\n",
            "Epoch 134/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.5650e-04\n",
            "Epoch 135/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.5317e-04\n",
            "Epoch 136/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.8092e-04\n",
            "Epoch 137/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.9540e-04\n",
            "Epoch 138/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.8192e-04\n",
            "Epoch 139/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.5972e-04\n",
            "Epoch 140/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.4889e-04\n",
            "Epoch 141/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.6193e-04\n",
            "Epoch 142/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.6163e-04\n",
            "Epoch 143/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.5731e-04\n",
            "Epoch 144/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.5785e-04\n",
            "Epoch 145/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.4513e-04\n",
            "Epoch 146/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.4462e-04\n",
            "Epoch 147/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.5009e-04\n",
            "Epoch 148/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.4288e-04\n",
            "Epoch 149/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.4712e-04\n",
            "Epoch 150/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 6.3555e-04\n",
            "Epoch 151/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 6.4080e-04\n",
            "Epoch 152/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 6.6782e-04\n",
            "Epoch 153/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.4512e-04\n",
            "Epoch 154/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.5679e-04\n",
            "Epoch 155/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.3472e-04\n",
            "Epoch 156/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 6.3524e-04\n",
            "Epoch 157/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.3846e-04\n",
            "Epoch 158/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 6.3754e-04\n",
            "Epoch 159/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.5869e-04\n",
            "Epoch 160/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.5797e-04\n",
            "Epoch 161/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.3585e-04\n",
            "Epoch 162/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.3937e-04\n",
            "Epoch 163/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.6333e-04\n",
            "Epoch 164/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.5876e-04\n",
            "Epoch 165/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.8681e-04\n",
            "Epoch 166/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.5477e-04\n",
            "Epoch 167/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.2338e-04\n",
            "Epoch 168/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.2271e-04\n",
            "Epoch 169/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 6.2260e-04\n",
            "Epoch 170/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.1729e-04\n",
            "Epoch 171/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.2275e-04\n",
            "Epoch 172/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.1593e-04\n",
            "Epoch 173/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.3093e-04\n",
            "Epoch 174/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.3755e-04\n",
            "Epoch 175/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.1620e-04\n",
            "Epoch 176/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.1362e-04\n",
            "Epoch 177/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.2182e-04\n",
            "Epoch 178/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.2030e-04\n",
            "Epoch 179/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.3641e-04\n",
            "Epoch 180/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.3955e-04\n",
            "Epoch 181/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.1009e-04\n",
            "Epoch 182/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.0876e-04\n",
            "Epoch 183/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.1302e-04\n",
            "Epoch 184/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.4364e-04\n",
            "Epoch 185/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.4611e-04\n",
            "Epoch 186/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.0504e-04\n",
            "Epoch 187/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 6.0823e-04\n",
            "Epoch 188/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 6.0739e-04\n",
            "Epoch 189/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 6.0647e-04\n",
            "Epoch 190/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 6.0915e-04\n",
            "Epoch 191/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.9782e-04\n",
            "Epoch 192/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.9615e-04\n",
            "Epoch 193/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 6.0338e-04\n",
            "Epoch 194/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.1705e-04\n",
            "Epoch 195/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.2836e-04\n",
            "Epoch 196/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 6.0569e-04\n",
            "Epoch 197/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.9959e-04\n",
            "Epoch 198/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.9167e-04\n",
            "Epoch 199/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.8679e-04\n",
            "Epoch 200/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.9547e-04\n",
            "Epoch 201/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.9737e-04\n",
            "Epoch 202/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.8724e-04\n",
            "Epoch 203/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.8320e-04\n",
            "Epoch 204/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.8367e-04\n",
            "Epoch 205/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.9781e-04\n",
            "Epoch 206/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.8784e-04\n",
            "Epoch 207/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.9846e-04\n",
            "Epoch 208/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 6.0020e-04\n",
            "Epoch 209/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.8706e-04\n",
            "Epoch 210/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.8824e-04\n",
            "Epoch 211/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.9245e-04\n",
            "Epoch 212/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.8426e-04\n",
            "Epoch 213/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.7253e-04\n",
            "Epoch 214/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.7751e-04\n",
            "Epoch 215/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.7166e-04\n",
            "Epoch 216/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.6991e-04\n",
            "Epoch 217/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.7777e-04\n",
            "Epoch 218/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.7796e-04\n",
            "Epoch 219/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.6608e-04\n",
            "Epoch 220/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.6686e-04\n",
            "Epoch 221/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.7794e-04\n",
            "Epoch 222/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.6554e-04\n",
            "Epoch 223/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.9072e-04\n",
            "Epoch 224/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.6240e-04\n",
            "Epoch 225/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.6524e-04\n",
            "Epoch 226/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.6973e-04\n",
            "Epoch 227/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.9889e-04\n",
            "Epoch 228/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.5970e-04\n",
            "Epoch 229/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.5701e-04\n",
            "Epoch 230/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.5951e-04\n",
            "Epoch 231/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.1076e-04\n",
            "Epoch 232/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 6.0302e-04\n",
            "Epoch 233/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.8422e-04\n",
            "Epoch 234/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.6257e-04\n",
            "Epoch 235/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.5808e-04\n",
            "Epoch 236/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.7172e-04\n",
            "Epoch 237/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.7307e-04\n",
            "Epoch 238/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.6585e-04\n",
            "Epoch 239/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.7589e-04\n",
            "Epoch 240/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.6858e-04\n",
            "Epoch 241/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.5715e-04\n",
            "Epoch 242/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.5077e-04\n",
            "Epoch 243/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.5125e-04\n",
            "Epoch 244/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.5162e-04\n",
            "Epoch 245/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.6498e-04\n",
            "Epoch 246/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.5692e-04\n",
            "Epoch 247/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4855e-04\n",
            "Epoch 248/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.5681e-04\n",
            "Epoch 249/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.4904e-04\n",
            "Epoch 250/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4588e-04\n",
            "Epoch 251/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.5911e-04\n",
            "Epoch 252/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.6499e-04\n",
            "Epoch 253/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.6658e-04\n",
            "Epoch 254/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.7158e-04\n",
            "Epoch 255/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.4762e-04\n",
            "Epoch 256/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.4915e-04\n",
            "Epoch 257/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.5841e-04\n",
            "Epoch 258/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.5078e-04\n",
            "Epoch 259/2000\n",
            "1566/1566 [==============================] - 0s 35us/step - loss: 5.8526e-04\n",
            "Epoch 260/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.7603e-04\n",
            "Epoch 261/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.5120e-04\n",
            "Epoch 262/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.5747e-04\n",
            "Epoch 263/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.7234e-04\n",
            "Epoch 264/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 6.1304e-04\n",
            "Epoch 265/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.5865e-04\n",
            "Epoch 266/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.5969e-04\n",
            "Epoch 267/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.5074e-04\n",
            "Epoch 268/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.4800e-04\n",
            "Epoch 269/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.4036e-04\n",
            "Epoch 270/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.4028e-04\n",
            "Epoch 271/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.4625e-04\n",
            "Epoch 272/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.4306e-04\n",
            "Epoch 273/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.6088e-04\n",
            "Epoch 274/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.5701e-04\n",
            "Epoch 275/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.8120e-04\n",
            "Epoch 276/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.9284e-04\n",
            "Epoch 277/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.8021e-04\n",
            "Epoch 278/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.5174e-04\n",
            "Epoch 279/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3792e-04\n",
            "Epoch 280/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3875e-04\n",
            "Epoch 281/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3901e-04\n",
            "Epoch 282/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3560e-04\n",
            "Epoch 283/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3848e-04\n",
            "Epoch 284/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.4485e-04\n",
            "Epoch 285/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.6018e-04\n",
            "Epoch 286/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.7836e-04\n",
            "Epoch 287/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.4209e-04\n",
            "Epoch 288/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.4818e-04\n",
            "Epoch 289/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.4487e-04\n",
            "Epoch 290/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3473e-04\n",
            "Epoch 291/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.4246e-04\n",
            "Epoch 292/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.5136e-04\n",
            "Epoch 293/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.6629e-04\n",
            "Epoch 294/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3653e-04\n",
            "Epoch 295/2000\n",
            "1566/1566 [==============================] - 0s 35us/step - loss: 5.4108e-04\n",
            "Epoch 296/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3201e-04\n",
            "Epoch 297/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.3519e-04\n",
            "Epoch 298/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3697e-04\n",
            "Epoch 299/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.4179e-04\n",
            "Epoch 300/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.4904e-04\n",
            "Epoch 301/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.4646e-04\n",
            "Epoch 302/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3644e-04\n",
            "Epoch 303/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3240e-04\n",
            "Epoch 304/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3388e-04\n",
            "Epoch 305/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3526e-04\n",
            "Epoch 306/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3446e-04\n",
            "Epoch 307/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3826e-04\n",
            "Epoch 308/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.4004e-04\n",
            "Epoch 309/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3939e-04\n",
            "Epoch 310/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3710e-04\n",
            "Epoch 311/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3442e-04\n",
            "Epoch 312/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.6230e-04\n",
            "Epoch 313/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.5723e-04\n",
            "Epoch 314/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3426e-04\n",
            "Epoch 315/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2989e-04\n",
            "Epoch 316/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3212e-04\n",
            "Epoch 317/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3100e-04\n",
            "Epoch 318/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3522e-04\n",
            "Epoch 319/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.4162e-04\n",
            "Epoch 320/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3013e-04\n",
            "Epoch 321/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3688e-04\n",
            "Epoch 322/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.4427e-04\n",
            "Epoch 323/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2718e-04\n",
            "Epoch 324/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3173e-04\n",
            "Epoch 325/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2836e-04\n",
            "Epoch 326/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.3285e-04\n",
            "Epoch 327/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.4047e-04\n",
            "Epoch 328/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.5242e-04\n",
            "Epoch 329/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2899e-04\n",
            "Epoch 330/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4792e-04\n",
            "Epoch 331/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.2966e-04\n",
            "Epoch 332/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3537e-04\n",
            "Epoch 333/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2616e-04\n",
            "Epoch 334/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.3265e-04\n",
            "Epoch 335/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3176e-04\n",
            "Epoch 336/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4596e-04\n",
            "Epoch 337/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.5232e-04\n",
            "Epoch 338/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3758e-04\n",
            "Epoch 339/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.4675e-04\n",
            "Epoch 340/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3373e-04\n",
            "Epoch 341/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3761e-04\n",
            "Epoch 342/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.3315e-04\n",
            "Epoch 343/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3303e-04\n",
            "Epoch 344/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2613e-04\n",
            "Epoch 345/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2540e-04\n",
            "Epoch 346/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.5216e-04\n",
            "Epoch 347/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.4604e-04\n",
            "Epoch 348/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.4016e-04\n",
            "Epoch 349/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3785e-04\n",
            "Epoch 350/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3435e-04\n",
            "Epoch 351/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.2455e-04\n",
            "Epoch 352/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2993e-04\n",
            "Epoch 353/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.2947e-04\n",
            "Epoch 354/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4283e-04\n",
            "Epoch 355/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3704e-04\n",
            "Epoch 356/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3562e-04\n",
            "Epoch 357/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2944e-04\n",
            "Epoch 358/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2195e-04\n",
            "Epoch 359/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4103e-04\n",
            "Epoch 360/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4352e-04\n",
            "Epoch 361/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3026e-04\n",
            "Epoch 362/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2121e-04\n",
            "Epoch 363/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2247e-04\n",
            "Epoch 364/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2129e-04\n",
            "Epoch 365/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2828e-04\n",
            "Epoch 366/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2538e-04\n",
            "Epoch 367/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3259e-04\n",
            "Epoch 368/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.4396e-04\n",
            "Epoch 369/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.5702e-04\n",
            "Epoch 370/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.7115e-04\n",
            "Epoch 371/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.6282e-04\n",
            "Epoch 372/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3489e-04\n",
            "Epoch 373/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2192e-04\n",
            "Epoch 374/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1993e-04\n",
            "Epoch 375/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3115e-04\n",
            "Epoch 376/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3549e-04\n",
            "Epoch 377/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2419e-04\n",
            "Epoch 378/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.4151e-04\n",
            "Epoch 379/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2172e-04\n",
            "Epoch 380/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2230e-04\n",
            "Epoch 381/2000\n",
            "1566/1566 [==============================] - 0s 35us/step - loss: 5.2183e-04\n",
            "Epoch 382/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.4525e-04\n",
            "Epoch 383/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.4988e-04\n",
            "Epoch 384/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2127e-04\n",
            "Epoch 385/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2262e-04\n",
            "Epoch 386/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2375e-04\n",
            "Epoch 387/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2257e-04\n",
            "Epoch 388/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3632e-04\n",
            "Epoch 389/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2834e-04\n",
            "Epoch 390/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2211e-04\n",
            "Epoch 391/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1964e-04\n",
            "Epoch 392/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1817e-04\n",
            "Epoch 393/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2213e-04\n",
            "Epoch 394/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1998e-04\n",
            "Epoch 395/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2097e-04\n",
            "Epoch 396/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2418e-04\n",
            "Epoch 397/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3758e-04\n",
            "Epoch 398/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2574e-04\n",
            "Epoch 399/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2159e-04\n",
            "Epoch 400/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2773e-04\n",
            "Epoch 401/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2185e-04\n",
            "Epoch 402/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1648e-04\n",
            "Epoch 403/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1664e-04\n",
            "Epoch 404/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.2243e-04\n",
            "Epoch 405/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1815e-04\n",
            "Epoch 406/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2036e-04\n",
            "Epoch 407/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2760e-04\n",
            "Epoch 408/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1951e-04\n",
            "Epoch 409/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1621e-04\n",
            "Epoch 410/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2811e-04\n",
            "Epoch 411/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3969e-04\n",
            "Epoch 412/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1783e-04\n",
            "Epoch 413/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2528e-04\n",
            "Epoch 414/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2165e-04\n",
            "Epoch 415/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.2219e-04\n",
            "Epoch 416/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2624e-04\n",
            "Epoch 417/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.1700e-04\n",
            "Epoch 418/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.1688e-04\n",
            "Epoch 419/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2760e-04\n",
            "Epoch 420/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2158e-04\n",
            "Epoch 421/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2529e-04\n",
            "Epoch 422/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3006e-04\n",
            "Epoch 423/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1209e-04\n",
            "Epoch 424/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2419e-04\n",
            "Epoch 425/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1776e-04\n",
            "Epoch 426/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2123e-04\n",
            "Epoch 427/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2219e-04\n",
            "Epoch 428/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2463e-04\n",
            "Epoch 429/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.4412e-04\n",
            "Epoch 430/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3534e-04\n",
            "Epoch 431/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.2266e-04\n",
            "Epoch 432/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2648e-04\n",
            "Epoch 433/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.4017e-04\n",
            "Epoch 434/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2410e-04\n",
            "Epoch 435/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1386e-04\n",
            "Epoch 436/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2337e-04\n",
            "Epoch 437/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.1591e-04\n",
            "Epoch 438/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1532e-04\n",
            "Epoch 439/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.2363e-04\n",
            "Epoch 440/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2620e-04\n",
            "Epoch 441/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2439e-04\n",
            "Epoch 442/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1899e-04\n",
            "Epoch 443/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2233e-04\n",
            "Epoch 444/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.2424e-04\n",
            "Epoch 445/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1668e-04\n",
            "Epoch 446/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1140e-04\n",
            "Epoch 447/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1506e-04\n",
            "Epoch 448/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3089e-04\n",
            "Epoch 449/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2170e-04\n",
            "Epoch 450/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2354e-04\n",
            "Epoch 451/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2104e-04\n",
            "Epoch 452/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1677e-04\n",
            "Epoch 453/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.6170e-04\n",
            "Epoch 454/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2987e-04\n",
            "Epoch 455/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2312e-04\n",
            "Epoch 456/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2867e-04\n",
            "Epoch 457/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1458e-04\n",
            "Epoch 458/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2104e-04\n",
            "Epoch 459/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2036e-04\n",
            "Epoch 460/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3576e-04\n",
            "Epoch 461/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.5074e-04\n",
            "Epoch 462/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.5280e-04\n",
            "Epoch 463/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2294e-04\n",
            "Epoch 464/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2809e-04\n",
            "Epoch 465/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.1751e-04\n",
            "Epoch 466/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3398e-04\n",
            "Epoch 467/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1165e-04\n",
            "Epoch 468/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1016e-04\n",
            "Epoch 469/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1500e-04\n",
            "Epoch 470/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3004e-04\n",
            "Epoch 471/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3526e-04\n",
            "Epoch 472/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.5132e-04\n",
            "Epoch 473/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.7378e-04\n",
            "Epoch 474/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2329e-04\n",
            "Epoch 475/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2460e-04\n",
            "Epoch 476/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2327e-04\n",
            "Epoch 477/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3235e-04\n",
            "Epoch 478/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3639e-04\n",
            "Epoch 479/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1369e-04\n",
            "Epoch 480/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1164e-04\n",
            "Epoch 481/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1506e-04\n",
            "Epoch 482/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1376e-04\n",
            "Epoch 483/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2768e-04\n",
            "Epoch 484/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0911e-04\n",
            "Epoch 485/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2410e-04\n",
            "Epoch 486/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1115e-04\n",
            "Epoch 487/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2022e-04\n",
            "Epoch 488/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2066e-04\n",
            "Epoch 489/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1067e-04\n",
            "Epoch 490/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0725e-04\n",
            "Epoch 491/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.1703e-04\n",
            "Epoch 492/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1692e-04\n",
            "Epoch 493/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3355e-04\n",
            "Epoch 494/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3905e-04\n",
            "Epoch 495/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.4485e-04\n",
            "Epoch 496/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1525e-04\n",
            "Epoch 497/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1090e-04\n",
            "Epoch 498/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1207e-04\n",
            "Epoch 499/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1828e-04\n",
            "Epoch 500/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1895e-04\n",
            "Epoch 501/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1160e-04\n",
            "Epoch 502/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0973e-04\n",
            "Epoch 503/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1330e-04\n",
            "Epoch 504/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0796e-04\n",
            "Epoch 505/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1260e-04\n",
            "Epoch 506/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1894e-04\n",
            "Epoch 507/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0668e-04\n",
            "Epoch 508/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2248e-04\n",
            "Epoch 509/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3403e-04\n",
            "Epoch 510/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.4942e-04\n",
            "Epoch 511/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2573e-04\n",
            "Epoch 512/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1587e-04\n",
            "Epoch 513/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.3594e-04\n",
            "Epoch 514/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1281e-04\n",
            "Epoch 515/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2559e-04\n",
            "Epoch 516/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1352e-04\n",
            "Epoch 517/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1150e-04\n",
            "Epoch 518/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.4068e-04\n",
            "Epoch 519/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1709e-04\n",
            "Epoch 520/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2018e-04\n",
            "Epoch 521/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2291e-04\n",
            "Epoch 522/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2053e-04\n",
            "Epoch 523/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0977e-04\n",
            "Epoch 524/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0997e-04\n",
            "Epoch 525/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0671e-04\n",
            "Epoch 526/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1382e-04\n",
            "Epoch 527/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1022e-04\n",
            "Epoch 528/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1452e-04\n",
            "Epoch 529/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1959e-04\n",
            "Epoch 530/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3549e-04\n",
            "Epoch 531/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3158e-04\n",
            "Epoch 532/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0392e-04\n",
            "Epoch 533/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1131e-04\n",
            "Epoch 534/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0912e-04\n",
            "Epoch 535/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0611e-04\n",
            "Epoch 536/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0884e-04\n",
            "Epoch 537/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0729e-04\n",
            "Epoch 538/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1357e-04\n",
            "Epoch 539/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2164e-04\n",
            "Epoch 540/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0817e-04\n",
            "Epoch 541/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0845e-04\n",
            "Epoch 542/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3887e-04\n",
            "Epoch 543/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2956e-04\n",
            "Epoch 544/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0737e-04\n",
            "Epoch 545/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0807e-04\n",
            "Epoch 546/2000\n",
            "1566/1566 [==============================] - 0s 44us/step - loss: 5.1056e-04\n",
            "Epoch 547/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1590e-04\n",
            "Epoch 548/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3346e-04\n",
            "Epoch 549/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3454e-04\n",
            "Epoch 550/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0780e-04\n",
            "Epoch 551/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0632e-04\n",
            "Epoch 552/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0760e-04\n",
            "Epoch 553/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1720e-04\n",
            "Epoch 554/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1791e-04\n",
            "Epoch 555/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0988e-04\n",
            "Epoch 556/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0792e-04\n",
            "Epoch 557/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0407e-04\n",
            "Epoch 558/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1283e-04\n",
            "Epoch 559/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2228e-04\n",
            "Epoch 560/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1987e-04\n",
            "Epoch 561/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1129e-04\n",
            "Epoch 562/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1269e-04\n",
            "Epoch 563/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0760e-04\n",
            "Epoch 564/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0554e-04\n",
            "Epoch 565/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1933e-04\n",
            "Epoch 566/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1244e-04\n",
            "Epoch 567/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1873e-04\n",
            "Epoch 568/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3152e-04\n",
            "Epoch 569/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0449e-04\n",
            "Epoch 570/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1950e-04\n",
            "Epoch 571/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1158e-04\n",
            "Epoch 572/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3428e-04\n",
            "Epoch 573/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0461e-04\n",
            "Epoch 574/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1056e-04\n",
            "Epoch 575/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0726e-04\n",
            "Epoch 576/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1016e-04\n",
            "Epoch 577/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0307e-04\n",
            "Epoch 578/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0801e-04\n",
            "Epoch 579/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0920e-04\n",
            "Epoch 580/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.0999e-04\n",
            "Epoch 581/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1146e-04\n",
            "Epoch 582/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0833e-04\n",
            "Epoch 583/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0863e-04\n",
            "Epoch 584/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0963e-04\n",
            "Epoch 585/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2070e-04\n",
            "Epoch 586/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.4126e-04\n",
            "Epoch 587/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3347e-04\n",
            "Epoch 588/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1353e-04\n",
            "Epoch 589/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1165e-04\n",
            "Epoch 590/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0641e-04\n",
            "Epoch 591/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1513e-04\n",
            "Epoch 592/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1538e-04\n",
            "Epoch 593/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3520e-04\n",
            "Epoch 594/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2691e-04\n",
            "Epoch 595/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.3050e-04\n",
            "Epoch 596/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1767e-04\n",
            "Epoch 597/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0661e-04\n",
            "Epoch 598/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0577e-04\n",
            "Epoch 599/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0398e-04\n",
            "Epoch 600/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0609e-04\n",
            "Epoch 601/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0885e-04\n",
            "Epoch 602/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1348e-04\n",
            "Epoch 603/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0588e-04\n",
            "Epoch 604/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0835e-04\n",
            "Epoch 605/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1948e-04\n",
            "Epoch 606/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0919e-04\n",
            "Epoch 607/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0203e-04\n",
            "Epoch 608/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0360e-04\n",
            "Epoch 609/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0932e-04\n",
            "Epoch 610/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0704e-04\n",
            "Epoch 611/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0612e-04\n",
            "Epoch 612/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0893e-04\n",
            "Epoch 613/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0655e-04\n",
            "Epoch 614/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2402e-04\n",
            "Epoch 615/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0459e-04\n",
            "Epoch 616/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0245e-04\n",
            "Epoch 617/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1049e-04\n",
            "Epoch 618/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0616e-04\n",
            "Epoch 619/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2094e-04\n",
            "Epoch 620/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1328e-04\n",
            "Epoch 621/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1287e-04\n",
            "Epoch 622/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0982e-04\n",
            "Epoch 623/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0713e-04\n",
            "Epoch 624/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0231e-04\n",
            "Epoch 625/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.0734e-04\n",
            "Epoch 626/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1223e-04\n",
            "Epoch 627/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0312e-04\n",
            "Epoch 628/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1189e-04\n",
            "Epoch 629/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1263e-04\n",
            "Epoch 630/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.1689e-04\n",
            "Epoch 631/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1807e-04\n",
            "Epoch 632/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0153e-04\n",
            "Epoch 633/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0809e-04\n",
            "Epoch 634/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2046e-04\n",
            "Epoch 635/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1743e-04\n",
            "Epoch 636/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2260e-04\n",
            "Epoch 637/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0806e-04\n",
            "Epoch 638/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1510e-04\n",
            "Epoch 639/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1151e-04\n",
            "Epoch 640/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.2746e-04\n",
            "Epoch 641/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1098e-04\n",
            "Epoch 642/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0938e-04\n",
            "Epoch 643/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.0394e-04\n",
            "Epoch 644/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0591e-04\n",
            "Epoch 645/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0146e-04\n",
            "Epoch 646/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2026e-04\n",
            "Epoch 647/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2646e-04\n",
            "Epoch 648/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2306e-04\n",
            "Epoch 649/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0600e-04\n",
            "Epoch 650/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1269e-04\n",
            "Epoch 651/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2375e-04\n",
            "Epoch 652/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1664e-04\n",
            "Epoch 653/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0854e-04\n",
            "Epoch 654/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0059e-04\n",
            "Epoch 655/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0536e-04\n",
            "Epoch 656/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0602e-04\n",
            "Epoch 657/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0384e-04\n",
            "Epoch 658/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0253e-04\n",
            "Epoch 659/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0672e-04\n",
            "Epoch 660/2000\n",
            "1566/1566 [==============================] - 0s 35us/step - loss: 5.0632e-04\n",
            "Epoch 661/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1022e-04\n",
            "Epoch 662/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0830e-04\n",
            "Epoch 663/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1197e-04\n",
            "Epoch 664/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0189e-04\n",
            "Epoch 665/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9987e-04\n",
            "Epoch 666/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2062e-04\n",
            "Epoch 667/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0377e-04\n",
            "Epoch 668/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0577e-04\n",
            "Epoch 669/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0445e-04\n",
            "Epoch 670/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1376e-04\n",
            "Epoch 671/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4821e-04\n",
            "Epoch 672/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2824e-04\n",
            "Epoch 673/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0278e-04\n",
            "Epoch 674/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0302e-04\n",
            "Epoch 675/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0502e-04\n",
            "Epoch 676/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1020e-04\n",
            "Epoch 677/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0960e-04\n",
            "Epoch 678/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.0329e-04\n",
            "Epoch 679/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0359e-04\n",
            "Epoch 680/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0487e-04\n",
            "Epoch 681/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0215e-04\n",
            "Epoch 682/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0194e-04\n",
            "Epoch 683/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1852e-04\n",
            "Epoch 684/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0348e-04\n",
            "Epoch 685/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0231e-04\n",
            "Epoch 686/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0258e-04\n",
            "Epoch 687/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.2756e-04\n",
            "Epoch 688/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0691e-04\n",
            "Epoch 689/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.0505e-04\n",
            "Epoch 690/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0769e-04\n",
            "Epoch 691/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.1121e-04\n",
            "Epoch 692/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0794e-04\n",
            "Epoch 693/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0142e-04\n",
            "Epoch 694/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.0528e-04\n",
            "Epoch 695/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0557e-04\n",
            "Epoch 696/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0461e-04\n",
            "Epoch 697/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0472e-04\n",
            "Epoch 698/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.0837e-04\n",
            "Epoch 699/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1730e-04\n",
            "Epoch 700/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0785e-04\n",
            "Epoch 701/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1130e-04\n",
            "Epoch 702/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0681e-04\n",
            "Epoch 703/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.1726e-04\n",
            "Epoch 704/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3459e-04\n",
            "Epoch 705/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0319e-04\n",
            "Epoch 706/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1996e-04\n",
            "Epoch 707/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1369e-04\n",
            "Epoch 708/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0900e-04\n",
            "Epoch 709/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0709e-04\n",
            "Epoch 710/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1164e-04\n",
            "Epoch 711/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2019e-04\n",
            "Epoch 712/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0340e-04\n",
            "Epoch 713/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0138e-04\n",
            "Epoch 714/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0896e-04\n",
            "Epoch 715/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2319e-04\n",
            "Epoch 716/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.0086e-04\n",
            "Epoch 717/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0702e-04\n",
            "Epoch 718/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0486e-04\n",
            "Epoch 719/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1063e-04\n",
            "Epoch 720/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0266e-04\n",
            "Epoch 721/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9886e-04\n",
            "Epoch 722/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1529e-04\n",
            "Epoch 723/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0385e-04\n",
            "Epoch 724/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1172e-04\n",
            "Epoch 725/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0541e-04\n",
            "Epoch 726/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3735e-04\n",
            "Epoch 727/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0691e-04\n",
            "Epoch 728/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0384e-04\n",
            "Epoch 729/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0529e-04\n",
            "Epoch 730/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.0197e-04\n",
            "Epoch 731/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0072e-04\n",
            "Epoch 732/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.2314e-04\n",
            "Epoch 733/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0769e-04\n",
            "Epoch 734/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3743e-04\n",
            "Epoch 735/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1818e-04\n",
            "Epoch 736/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0773e-04\n",
            "Epoch 737/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0510e-04\n",
            "Epoch 738/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1245e-04\n",
            "Epoch 739/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1460e-04\n",
            "Epoch 740/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1340e-04\n",
            "Epoch 741/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0096e-04\n",
            "Epoch 742/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2217e-04\n",
            "Epoch 743/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2434e-04\n",
            "Epoch 744/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1505e-04\n",
            "Epoch 745/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1510e-04\n",
            "Epoch 746/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0793e-04\n",
            "Epoch 747/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.5130e-04\n",
            "Epoch 748/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3429e-04\n",
            "Epoch 749/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3994e-04\n",
            "Epoch 750/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1141e-04\n",
            "Epoch 751/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0301e-04\n",
            "Epoch 752/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0722e-04\n",
            "Epoch 753/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9897e-04\n",
            "Epoch 754/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1139e-04\n",
            "Epoch 755/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0845e-04\n",
            "Epoch 756/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0065e-04\n",
            "Epoch 757/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1387e-04\n",
            "Epoch 758/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0418e-04\n",
            "Epoch 759/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0823e-04\n",
            "Epoch 760/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1788e-04\n",
            "Epoch 761/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0154e-04\n",
            "Epoch 762/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0200e-04\n",
            "Epoch 763/2000\n",
            "1566/1566 [==============================] - 0s 36us/step - loss: 5.0434e-04\n",
            "Epoch 764/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9916e-04\n",
            "Epoch 765/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0536e-04\n",
            "Epoch 766/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1923e-04\n",
            "Epoch 767/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0538e-04\n",
            "Epoch 768/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3554e-04\n",
            "Epoch 769/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.1527e-04\n",
            "Epoch 770/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0835e-04\n",
            "Epoch 771/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0665e-04\n",
            "Epoch 772/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0827e-04\n",
            "Epoch 773/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1279e-04\n",
            "Epoch 774/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1758e-04\n",
            "Epoch 775/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0365e-04\n",
            "Epoch 776/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9806e-04\n",
            "Epoch 777/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 4.9890e-04\n",
            "Epoch 778/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0425e-04\n",
            "Epoch 779/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0426e-04\n",
            "Epoch 780/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0372e-04\n",
            "Epoch 781/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0055e-04\n",
            "Epoch 782/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0637e-04\n",
            "Epoch 783/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1075e-04\n",
            "Epoch 784/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0651e-04\n",
            "Epoch 785/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0563e-04\n",
            "Epoch 786/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9725e-04\n",
            "Epoch 787/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0756e-04\n",
            "Epoch 788/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0399e-04\n",
            "Epoch 789/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0640e-04\n",
            "Epoch 790/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0455e-04\n",
            "Epoch 791/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3029e-04\n",
            "Epoch 792/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0837e-04\n",
            "Epoch 793/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1100e-04\n",
            "Epoch 794/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0739e-04\n",
            "Epoch 795/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0494e-04\n",
            "Epoch 796/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1365e-04\n",
            "Epoch 797/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2088e-04\n",
            "Epoch 798/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3336e-04\n",
            "Epoch 799/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9930e-04\n",
            "Epoch 800/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0097e-04\n",
            "Epoch 801/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0315e-04\n",
            "Epoch 802/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1853e-04\n",
            "Epoch 803/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0896e-04\n",
            "Epoch 804/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0240e-04\n",
            "Epoch 805/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0685e-04\n",
            "Epoch 806/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1080e-04\n",
            "Epoch 807/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0723e-04\n",
            "Epoch 808/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1011e-04\n",
            "Epoch 809/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3622e-04\n",
            "Epoch 810/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2106e-04\n",
            "Epoch 811/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0688e-04\n",
            "Epoch 812/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0158e-04\n",
            "Epoch 813/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0825e-04\n",
            "Epoch 814/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3568e-04\n",
            "Epoch 815/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0067e-04\n",
            "Epoch 816/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0921e-04\n",
            "Epoch 817/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0975e-04\n",
            "Epoch 818/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2492e-04\n",
            "Epoch 819/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1289e-04\n",
            "Epoch 820/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1261e-04\n",
            "Epoch 821/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1577e-04\n",
            "Epoch 822/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0886e-04\n",
            "Epoch 823/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0106e-04\n",
            "Epoch 824/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0346e-04\n",
            "Epoch 825/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0667e-04\n",
            "Epoch 826/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0402e-04\n",
            "Epoch 827/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0090e-04\n",
            "Epoch 828/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9925e-04\n",
            "Epoch 829/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0144e-04\n",
            "Epoch 830/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9974e-04\n",
            "Epoch 831/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0425e-04\n",
            "Epoch 832/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0596e-04\n",
            "Epoch 833/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3219e-04\n",
            "Epoch 834/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1628e-04\n",
            "Epoch 835/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0054e-04\n",
            "Epoch 836/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0727e-04\n",
            "Epoch 837/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1153e-04\n",
            "Epoch 838/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0114e-04\n",
            "Epoch 839/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0839e-04\n",
            "Epoch 840/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9909e-04\n",
            "Epoch 841/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 4.9994e-04\n",
            "Epoch 842/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0672e-04\n",
            "Epoch 843/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0539e-04\n",
            "Epoch 844/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0405e-04\n",
            "Epoch 845/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0149e-04\n",
            "Epoch 846/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0114e-04\n",
            "Epoch 847/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0068e-04\n",
            "Epoch 848/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0853e-04\n",
            "Epoch 849/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9842e-04\n",
            "Epoch 850/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0044e-04\n",
            "Epoch 851/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0837e-04\n",
            "Epoch 852/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0158e-04\n",
            "Epoch 853/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2288e-04\n",
            "Epoch 854/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0730e-04\n",
            "Epoch 855/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.1361e-04\n",
            "Epoch 856/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.4789e-04\n",
            "Epoch 857/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0613e-04\n",
            "Epoch 858/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2803e-04\n",
            "Epoch 859/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0078e-04\n",
            "Epoch 860/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1348e-04\n",
            "Epoch 861/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0148e-04\n",
            "Epoch 862/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0113e-04\n",
            "Epoch 863/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9981e-04\n",
            "Epoch 864/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0099e-04\n",
            "Epoch 865/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0590e-04\n",
            "Epoch 866/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1440e-04\n",
            "Epoch 867/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1239e-04\n",
            "Epoch 868/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4261e-04\n",
            "Epoch 869/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3052e-04\n",
            "Epoch 870/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1770e-04\n",
            "Epoch 871/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0033e-04\n",
            "Epoch 872/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0955e-04\n",
            "Epoch 873/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1808e-04\n",
            "Epoch 874/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0914e-04\n",
            "Epoch 875/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.2023e-04\n",
            "Epoch 876/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2267e-04\n",
            "Epoch 877/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1708e-04\n",
            "Epoch 878/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9710e-04\n",
            "Epoch 879/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9947e-04\n",
            "Epoch 880/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 4.9886e-04\n",
            "Epoch 881/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0976e-04\n",
            "Epoch 882/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0879e-04\n",
            "Epoch 883/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0163e-04\n",
            "Epoch 884/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 4.9670e-04\n",
            "Epoch 885/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0282e-04\n",
            "Epoch 886/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0826e-04\n",
            "Epoch 887/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1744e-04\n",
            "Epoch 888/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9983e-04\n",
            "Epoch 889/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9938e-04\n",
            "Epoch 890/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0252e-04\n",
            "Epoch 891/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0764e-04\n",
            "Epoch 892/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0199e-04\n",
            "Epoch 893/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9847e-04\n",
            "Epoch 894/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0031e-04\n",
            "Epoch 895/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0822e-04\n",
            "Epoch 896/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0091e-04\n",
            "Epoch 897/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.1087e-04\n",
            "Epoch 898/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9976e-04\n",
            "Epoch 899/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1167e-04\n",
            "Epoch 900/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0947e-04\n",
            "Epoch 901/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9948e-04\n",
            "Epoch 902/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1002e-04\n",
            "Epoch 903/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1882e-04\n",
            "Epoch 904/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0499e-04\n",
            "Epoch 905/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0898e-04\n",
            "Epoch 906/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0250e-04\n",
            "Epoch 907/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0642e-04\n",
            "Epoch 908/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0749e-04\n",
            "Epoch 909/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0104e-04\n",
            "Epoch 910/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0837e-04\n",
            "Epoch 911/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0542e-04\n",
            "Epoch 912/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1538e-04\n",
            "Epoch 913/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3043e-04\n",
            "Epoch 914/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0170e-04\n",
            "Epoch 915/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0624e-04\n",
            "Epoch 916/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.1537e-04\n",
            "Epoch 917/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1345e-04\n",
            "Epoch 918/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9995e-04\n",
            "Epoch 919/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 4.9648e-04\n",
            "Epoch 920/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0968e-04\n",
            "Epoch 921/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9992e-04\n",
            "Epoch 922/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0659e-04\n",
            "Epoch 923/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0661e-04\n",
            "Epoch 924/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 4.9810e-04\n",
            "Epoch 925/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0458e-04\n",
            "Epoch 926/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0771e-04\n",
            "Epoch 927/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0733e-04\n",
            "Epoch 928/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0274e-04\n",
            "Epoch 929/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0985e-04\n",
            "Epoch 930/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0785e-04\n",
            "Epoch 931/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1189e-04\n",
            "Epoch 932/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9812e-04\n",
            "Epoch 933/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0654e-04\n",
            "Epoch 934/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.2131e-04\n",
            "Epoch 935/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9774e-04\n",
            "Epoch 936/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0394e-04\n",
            "Epoch 937/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0912e-04\n",
            "Epoch 938/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0806e-04\n",
            "Epoch 939/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0375e-04\n",
            "Epoch 940/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0484e-04\n",
            "Epoch 941/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9678e-04\n",
            "Epoch 942/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2355e-04\n",
            "Epoch 943/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2131e-04\n",
            "Epoch 944/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1224e-04\n",
            "Epoch 945/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0452e-04\n",
            "Epoch 946/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9997e-04\n",
            "Epoch 947/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9766e-04\n",
            "Epoch 948/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9767e-04\n",
            "Epoch 949/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0163e-04\n",
            "Epoch 950/2000\n",
            "1566/1566 [==============================] - 0s 36us/step - loss: 5.0398e-04\n",
            "Epoch 951/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1572e-04\n",
            "Epoch 952/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.2253e-04\n",
            "Epoch 953/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0668e-04\n",
            "Epoch 954/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0106e-04\n",
            "Epoch 955/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1090e-04\n",
            "Epoch 956/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0714e-04\n",
            "Epoch 957/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9689e-04\n",
            "Epoch 958/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9831e-04\n",
            "Epoch 959/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0476e-04\n",
            "Epoch 960/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2397e-04\n",
            "Epoch 961/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0615e-04\n",
            "Epoch 962/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0170e-04\n",
            "Epoch 963/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1834e-04\n",
            "Epoch 964/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0750e-04\n",
            "Epoch 965/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9797e-04\n",
            "Epoch 966/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.1188e-04\n",
            "Epoch 967/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0284e-04\n",
            "Epoch 968/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2853e-04\n",
            "Epoch 969/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3137e-04\n",
            "Epoch 970/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1695e-04\n",
            "Epoch 971/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2597e-04\n",
            "Epoch 972/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9941e-04\n",
            "Epoch 973/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9806e-04\n",
            "Epoch 974/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9852e-04\n",
            "Epoch 975/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9731e-04\n",
            "Epoch 976/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1007e-04\n",
            "Epoch 977/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.4193e-04\n",
            "Epoch 978/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2253e-04\n",
            "Epoch 979/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1851e-04\n",
            "Epoch 980/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1671e-04\n",
            "Epoch 981/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9840e-04\n",
            "Epoch 982/2000\n",
            "1566/1566 [==============================] - 0s 36us/step - loss: 4.9790e-04\n",
            "Epoch 983/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0348e-04\n",
            "Epoch 984/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1271e-04\n",
            "Epoch 985/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1970e-04\n",
            "Epoch 986/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0234e-04\n",
            "Epoch 987/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0342e-04\n",
            "Epoch 988/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0678e-04\n",
            "Epoch 989/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0850e-04\n",
            "Epoch 990/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0603e-04\n",
            "Epoch 991/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0495e-04\n",
            "Epoch 992/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0908e-04\n",
            "Epoch 993/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1593e-04\n",
            "Epoch 994/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2146e-04\n",
            "Epoch 995/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3146e-04\n",
            "Epoch 996/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.3011e-04\n",
            "Epoch 997/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0957e-04\n",
            "Epoch 998/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0054e-04\n",
            "Epoch 999/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9817e-04\n",
            "Epoch 1000/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0580e-04\n",
            "Epoch 1001/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1151e-04\n",
            "Epoch 1002/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0147e-04\n",
            "Epoch 1003/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2852e-04\n",
            "Epoch 1004/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0577e-04\n",
            "Epoch 1005/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1232e-04\n",
            "Epoch 1006/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.3117e-04\n",
            "Epoch 1007/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0558e-04\n",
            "Epoch 1008/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9474e-04\n",
            "Epoch 1009/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9532e-04\n",
            "Epoch 1010/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9817e-04\n",
            "Epoch 1011/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9889e-04\n",
            "Epoch 1012/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1307e-04\n",
            "Epoch 1013/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0546e-04\n",
            "Epoch 1014/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3113e-04\n",
            "Epoch 1015/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1328e-04\n",
            "Epoch 1016/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1458e-04\n",
            "Epoch 1017/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0785e-04\n",
            "Epoch 1018/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0593e-04\n",
            "Epoch 1019/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1129e-04\n",
            "Epoch 1020/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9643e-04\n",
            "Epoch 1021/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0934e-04\n",
            "Epoch 1022/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0633e-04\n",
            "Epoch 1023/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9847e-04\n",
            "Epoch 1024/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0006e-04\n",
            "Epoch 1025/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1522e-04\n",
            "Epoch 1026/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3149e-04\n",
            "Epoch 1027/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0190e-04\n",
            "Epoch 1028/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0598e-04\n",
            "Epoch 1029/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0256e-04\n",
            "Epoch 1030/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9975e-04\n",
            "Epoch 1031/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0120e-04\n",
            "Epoch 1032/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9571e-04\n",
            "Epoch 1033/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0001e-04\n",
            "Epoch 1034/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9919e-04\n",
            "Epoch 1035/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0260e-04\n",
            "Epoch 1036/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0355e-04\n",
            "Epoch 1037/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9608e-04\n",
            "Epoch 1038/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2160e-04\n",
            "Epoch 1039/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0655e-04\n",
            "Epoch 1040/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0609e-04\n",
            "Epoch 1041/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0140e-04\n",
            "Epoch 1042/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1513e-04\n",
            "Epoch 1043/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.2274e-04\n",
            "Epoch 1044/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.5520e-04\n",
            "Epoch 1045/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2728e-04\n",
            "Epoch 1046/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0639e-04\n",
            "Epoch 1047/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9947e-04\n",
            "Epoch 1048/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0018e-04\n",
            "Epoch 1049/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9739e-04\n",
            "Epoch 1050/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0691e-04\n",
            "Epoch 1051/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9946e-04\n",
            "Epoch 1052/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0920e-04\n",
            "Epoch 1053/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0786e-04\n",
            "Epoch 1054/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0675e-04\n",
            "Epoch 1055/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0489e-04\n",
            "Epoch 1056/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0230e-04\n",
            "Epoch 1057/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1340e-04\n",
            "Epoch 1058/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0183e-04\n",
            "Epoch 1059/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9906e-04\n",
            "Epoch 1060/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1132e-04\n",
            "Epoch 1061/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1378e-04\n",
            "Epoch 1062/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0793e-04\n",
            "Epoch 1063/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1409e-04\n",
            "Epoch 1064/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3122e-04\n",
            "Epoch 1065/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2679e-04\n",
            "Epoch 1066/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0270e-04\n",
            "Epoch 1067/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9571e-04\n",
            "Epoch 1068/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0080e-04\n",
            "Epoch 1069/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0278e-04\n",
            "Epoch 1070/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0534e-04\n",
            "Epoch 1071/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9997e-04\n",
            "Epoch 1072/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9525e-04\n",
            "Epoch 1073/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9840e-04\n",
            "Epoch 1074/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0198e-04\n",
            "Epoch 1075/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0082e-04\n",
            "Epoch 1076/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0068e-04\n",
            "Epoch 1077/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0585e-04\n",
            "Epoch 1078/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0003e-04\n",
            "Epoch 1079/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0365e-04\n",
            "Epoch 1080/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9878e-04\n",
            "Epoch 1081/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0491e-04\n",
            "Epoch 1082/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1070e-04\n",
            "Epoch 1083/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1950e-04\n",
            "Epoch 1084/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9936e-04\n",
            "Epoch 1085/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9674e-04\n",
            "Epoch 1086/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0427e-04\n",
            "Epoch 1087/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0694e-04\n",
            "Epoch 1088/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0332e-04\n",
            "Epoch 1089/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9866e-04\n",
            "Epoch 1090/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0988e-04\n",
            "Epoch 1091/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0074e-04\n",
            "Epoch 1092/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9757e-04\n",
            "Epoch 1093/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9668e-04\n",
            "Epoch 1094/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0163e-04\n",
            "Epoch 1095/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0491e-04\n",
            "Epoch 1096/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0902e-04\n",
            "Epoch 1097/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9802e-04\n",
            "Epoch 1098/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0037e-04\n",
            "Epoch 1099/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9824e-04\n",
            "Epoch 1100/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0400e-04\n",
            "Epoch 1101/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9716e-04\n",
            "Epoch 1102/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0236e-04\n",
            "Epoch 1103/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0353e-04\n",
            "Epoch 1104/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9385e-04\n",
            "Epoch 1105/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0402e-04\n",
            "Epoch 1106/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0002e-04\n",
            "Epoch 1107/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9567e-04\n",
            "Epoch 1108/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0535e-04\n",
            "Epoch 1109/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1022e-04\n",
            "Epoch 1110/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9813e-04\n",
            "Epoch 1111/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0467e-04\n",
            "Epoch 1112/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0344e-04\n",
            "Epoch 1113/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0519e-04\n",
            "Epoch 1114/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9973e-04\n",
            "Epoch 1115/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0713e-04\n",
            "Epoch 1116/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0120e-04\n",
            "Epoch 1117/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9829e-04\n",
            "Epoch 1118/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0139e-04\n",
            "Epoch 1119/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0021e-04\n",
            "Epoch 1120/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1754e-04\n",
            "Epoch 1121/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0137e-04\n",
            "Epoch 1122/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0342e-04\n",
            "Epoch 1123/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1530e-04\n",
            "Epoch 1124/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2525e-04\n",
            "Epoch 1125/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9602e-04\n",
            "Epoch 1126/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0040e-04\n",
            "Epoch 1127/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9860e-04\n",
            "Epoch 1128/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0225e-04\n",
            "Epoch 1129/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1547e-04\n",
            "Epoch 1130/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0659e-04\n",
            "Epoch 1131/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9827e-04\n",
            "Epoch 1132/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1437e-04\n",
            "Epoch 1133/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0546e-04\n",
            "Epoch 1134/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0110e-04\n",
            "Epoch 1135/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9667e-04\n",
            "Epoch 1136/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9941e-04\n",
            "Epoch 1137/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1902e-04\n",
            "Epoch 1138/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9822e-04\n",
            "Epoch 1139/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0274e-04\n",
            "Epoch 1140/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1169e-04\n",
            "Epoch 1141/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2134e-04\n",
            "Epoch 1142/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1071e-04\n",
            "Epoch 1143/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0524e-04\n",
            "Epoch 1144/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0604e-04\n",
            "Epoch 1145/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0445e-04\n",
            "Epoch 1146/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9986e-04\n",
            "Epoch 1147/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9830e-04\n",
            "Epoch 1148/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0613e-04\n",
            "Epoch 1149/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0874e-04\n",
            "Epoch 1150/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0250e-04\n",
            "Epoch 1151/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9523e-04\n",
            "Epoch 1152/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0241e-04\n",
            "Epoch 1153/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3497e-04\n",
            "Epoch 1154/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1799e-04\n",
            "Epoch 1155/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9804e-04\n",
            "Epoch 1156/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0097e-04\n",
            "Epoch 1157/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9887e-04\n",
            "Epoch 1158/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0080e-04\n",
            "Epoch 1159/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0163e-04\n",
            "Epoch 1160/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0221e-04\n",
            "Epoch 1161/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.3375e-04\n",
            "Epoch 1162/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1406e-04\n",
            "Epoch 1163/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0745e-04\n",
            "Epoch 1164/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9644e-04\n",
            "Epoch 1165/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9682e-04\n",
            "Epoch 1166/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0198e-04\n",
            "Epoch 1167/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2477e-04\n",
            "Epoch 1168/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0693e-04\n",
            "Epoch 1169/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.4137e-04\n",
            "Epoch 1170/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0340e-04\n",
            "Epoch 1171/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9826e-04\n",
            "Epoch 1172/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0525e-04\n",
            "Epoch 1173/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0625e-04\n",
            "Epoch 1174/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0268e-04\n",
            "Epoch 1175/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1540e-04\n",
            "Epoch 1176/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9836e-04\n",
            "Epoch 1177/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0369e-04\n",
            "Epoch 1178/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0018e-04\n",
            "Epoch 1179/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0266e-04\n",
            "Epoch 1180/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9944e-04\n",
            "Epoch 1181/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9565e-04\n",
            "Epoch 1182/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9933e-04\n",
            "Epoch 1183/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0994e-04\n",
            "Epoch 1184/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3952e-04\n",
            "Epoch 1185/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2046e-04\n",
            "Epoch 1186/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0021e-04\n",
            "Epoch 1187/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0681e-04\n",
            "Epoch 1188/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9930e-04\n",
            "Epoch 1189/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0305e-04\n",
            "Epoch 1190/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0045e-04\n",
            "Epoch 1191/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2673e-04\n",
            "Epoch 1192/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9702e-04\n",
            "Epoch 1193/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9726e-04\n",
            "Epoch 1194/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9747e-04\n",
            "Epoch 1195/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9627e-04\n",
            "Epoch 1196/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0863e-04\n",
            "Epoch 1197/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9471e-04\n",
            "Epoch 1198/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0188e-04\n",
            "Epoch 1199/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1893e-04\n",
            "Epoch 1200/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0628e-04\n",
            "Epoch 1201/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0137e-04\n",
            "Epoch 1202/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 4.9565e-04\n",
            "Epoch 1203/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0905e-04\n",
            "Epoch 1204/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0680e-04\n",
            "Epoch 1205/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0212e-04\n",
            "Epoch 1206/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0622e-04\n",
            "Epoch 1207/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0408e-04\n",
            "Epoch 1208/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9829e-04\n",
            "Epoch 1209/2000\n",
            "1566/1566 [==============================] - 0s 36us/step - loss: 5.0063e-04\n",
            "Epoch 1210/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 4.9672e-04\n",
            "Epoch 1211/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 4.9613e-04\n",
            "Epoch 1212/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2029e-04\n",
            "Epoch 1213/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1741e-04\n",
            "Epoch 1214/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3967e-04\n",
            "Epoch 1215/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1034e-04\n",
            "Epoch 1216/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1349e-04\n",
            "Epoch 1217/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0233e-04\n",
            "Epoch 1218/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.1634e-04\n",
            "Epoch 1219/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9769e-04\n",
            "Epoch 1220/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9488e-04\n",
            "Epoch 1221/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0422e-04\n",
            "Epoch 1222/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9727e-04\n",
            "Epoch 1223/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.0600e-04\n",
            "Epoch 1224/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 4.9787e-04\n",
            "Epoch 1225/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0374e-04\n",
            "Epoch 1226/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1259e-04\n",
            "Epoch 1227/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1465e-04\n",
            "Epoch 1228/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1691e-04\n",
            "Epoch 1229/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1984e-04\n",
            "Epoch 1230/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0042e-04\n",
            "Epoch 1231/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0183e-04\n",
            "Epoch 1232/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9959e-04\n",
            "Epoch 1233/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 4.9587e-04\n",
            "Epoch 1234/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0957e-04\n",
            "Epoch 1235/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9406e-04\n",
            "Epoch 1236/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9859e-04\n",
            "Epoch 1237/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1107e-04\n",
            "Epoch 1238/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1727e-04\n",
            "Epoch 1239/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0588e-04\n",
            "Epoch 1240/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2195e-04\n",
            "Epoch 1241/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1202e-04\n",
            "Epoch 1242/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9553e-04\n",
            "Epoch 1243/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9661e-04\n",
            "Epoch 1244/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0700e-04\n",
            "Epoch 1245/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2400e-04\n",
            "Epoch 1246/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9962e-04\n",
            "Epoch 1247/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1374e-04\n",
            "Epoch 1248/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1440e-04\n",
            "Epoch 1249/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0820e-04\n",
            "Epoch 1250/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1022e-04\n",
            "Epoch 1251/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0764e-04\n",
            "Epoch 1252/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0153e-04\n",
            "Epoch 1253/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.1397e-04\n",
            "Epoch 1254/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1217e-04\n",
            "Epoch 1255/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0564e-04\n",
            "Epoch 1256/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9510e-04\n",
            "Epoch 1257/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0594e-04\n",
            "Epoch 1258/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9847e-04\n",
            "Epoch 1259/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0533e-04\n",
            "Epoch 1260/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0228e-04\n",
            "Epoch 1261/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9874e-04\n",
            "Epoch 1262/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9394e-04\n",
            "Epoch 1263/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0096e-04\n",
            "Epoch 1264/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0139e-04\n",
            "Epoch 1265/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9662e-04\n",
            "Epoch 1266/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9793e-04\n",
            "Epoch 1267/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0832e-04\n",
            "Epoch 1268/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2438e-04\n",
            "Epoch 1269/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0015e-04\n",
            "Epoch 1270/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2071e-04\n",
            "Epoch 1271/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9910e-04\n",
            "Epoch 1272/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9947e-04\n",
            "Epoch 1273/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0468e-04\n",
            "Epoch 1274/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9489e-04\n",
            "Epoch 1275/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9683e-04\n",
            "Epoch 1276/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9513e-04\n",
            "Epoch 1277/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0776e-04\n",
            "Epoch 1278/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0116e-04\n",
            "Epoch 1279/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0074e-04\n",
            "Epoch 1280/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2084e-04\n",
            "Epoch 1281/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0049e-04\n",
            "Epoch 1282/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1094e-04\n",
            "Epoch 1283/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1472e-04\n",
            "Epoch 1284/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9562e-04\n",
            "Epoch 1285/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1668e-04\n",
            "Epoch 1286/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0871e-04\n",
            "Epoch 1287/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0172e-04\n",
            "Epoch 1288/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0451e-04\n",
            "Epoch 1289/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9863e-04\n",
            "Epoch 1290/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9904e-04\n",
            "Epoch 1291/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0141e-04\n",
            "Epoch 1292/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.2449e-04\n",
            "Epoch 1293/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1330e-04\n",
            "Epoch 1294/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0404e-04\n",
            "Epoch 1295/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0697e-04\n",
            "Epoch 1296/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2313e-04\n",
            "Epoch 1297/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.3631e-04\n",
            "Epoch 1298/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9655e-04\n",
            "Epoch 1299/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9638e-04\n",
            "Epoch 1300/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0381e-04\n",
            "Epoch 1301/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0467e-04\n",
            "Epoch 1302/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0378e-04\n",
            "Epoch 1303/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9687e-04\n",
            "Epoch 1304/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9923e-04\n",
            "Epoch 1305/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1978e-04\n",
            "Epoch 1306/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9719e-04\n",
            "Epoch 1307/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0933e-04\n",
            "Epoch 1308/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9607e-04\n",
            "Epoch 1309/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9597e-04\n",
            "Epoch 1310/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0177e-04\n",
            "Epoch 1311/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0181e-04\n",
            "Epoch 1312/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9634e-04\n",
            "Epoch 1313/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2556e-04\n",
            "Epoch 1314/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0524e-04\n",
            "Epoch 1315/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9500e-04\n",
            "Epoch 1316/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2693e-04\n",
            "Epoch 1317/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.2841e-04\n",
            "Epoch 1318/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0479e-04\n",
            "Epoch 1319/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9494e-04\n",
            "Epoch 1320/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1262e-04\n",
            "Epoch 1321/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1467e-04\n",
            "Epoch 1322/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2795e-04\n",
            "Epoch 1323/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1266e-04\n",
            "Epoch 1324/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0974e-04\n",
            "Epoch 1325/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0401e-04\n",
            "Epoch 1326/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9938e-04\n",
            "Epoch 1327/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0558e-04\n",
            "Epoch 1328/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0006e-04\n",
            "Epoch 1329/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1698e-04\n",
            "Epoch 1330/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0402e-04\n",
            "Epoch 1331/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0959e-04\n",
            "Epoch 1332/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9746e-04\n",
            "Epoch 1333/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0638e-04\n",
            "Epoch 1334/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2488e-04\n",
            "Epoch 1335/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0465e-04\n",
            "Epoch 1336/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2033e-04\n",
            "Epoch 1337/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3210e-04\n",
            "Epoch 1338/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0987e-04\n",
            "Epoch 1339/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0196e-04\n",
            "Epoch 1340/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9890e-04\n",
            "Epoch 1341/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1096e-04\n",
            "Epoch 1342/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9748e-04\n",
            "Epoch 1343/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9642e-04\n",
            "Epoch 1344/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0510e-04\n",
            "Epoch 1345/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0310e-04\n",
            "Epoch 1346/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1276e-04\n",
            "Epoch 1347/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9649e-04\n",
            "Epoch 1348/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9918e-04\n",
            "Epoch 1349/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1148e-04\n",
            "Epoch 1350/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0858e-04\n",
            "Epoch 1351/2000\n",
            "1566/1566 [==============================] - 0s 42us/step - loss: 5.0595e-04\n",
            "Epoch 1352/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0391e-04\n",
            "Epoch 1353/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0928e-04\n",
            "Epoch 1354/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0231e-04\n",
            "Epoch 1355/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0664e-04\n",
            "Epoch 1356/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1371e-04\n",
            "Epoch 1357/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1930e-04\n",
            "Epoch 1358/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0324e-04\n",
            "Epoch 1359/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9776e-04\n",
            "Epoch 1360/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0051e-04\n",
            "Epoch 1361/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3435e-04\n",
            "Epoch 1362/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1217e-04\n",
            "Epoch 1363/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0390e-04\n",
            "Epoch 1364/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0149e-04\n",
            "Epoch 1365/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9853e-04\n",
            "Epoch 1366/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0193e-04\n",
            "Epoch 1367/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0131e-04\n",
            "Epoch 1368/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0869e-04\n",
            "Epoch 1369/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3156e-04\n",
            "Epoch 1370/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1355e-04\n",
            "Epoch 1371/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9794e-04\n",
            "Epoch 1372/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9793e-04\n",
            "Epoch 1373/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9918e-04\n",
            "Epoch 1374/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9879e-04\n",
            "Epoch 1375/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9972e-04\n",
            "Epoch 1376/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0398e-04\n",
            "Epoch 1377/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0242e-04\n",
            "Epoch 1378/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1651e-04\n",
            "Epoch 1379/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9937e-04\n",
            "Epoch 1380/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9705e-04\n",
            "Epoch 1381/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0541e-04\n",
            "Epoch 1382/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0118e-04\n",
            "Epoch 1383/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9881e-04\n",
            "Epoch 1384/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9842e-04\n",
            "Epoch 1385/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0023e-04\n",
            "Epoch 1386/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9567e-04\n",
            "Epoch 1387/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9913e-04\n",
            "Epoch 1388/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0527e-04\n",
            "Epoch 1389/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.3709e-04\n",
            "Epoch 1390/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0078e-04\n",
            "Epoch 1391/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0729e-04\n",
            "Epoch 1392/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0218e-04\n",
            "Epoch 1393/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9470e-04\n",
            "Epoch 1394/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1874e-04\n",
            "Epoch 1395/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0367e-04\n",
            "Epoch 1396/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0182e-04\n",
            "Epoch 1397/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0322e-04\n",
            "Epoch 1398/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0264e-04\n",
            "Epoch 1399/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0663e-04\n",
            "Epoch 1400/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0308e-04\n",
            "Epoch 1401/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9714e-04\n",
            "Epoch 1402/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9761e-04\n",
            "Epoch 1403/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0117e-04\n",
            "Epoch 1404/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9980e-04\n",
            "Epoch 1405/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0433e-04\n",
            "Epoch 1406/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0882e-04\n",
            "Epoch 1407/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1616e-04\n",
            "Epoch 1408/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9903e-04\n",
            "Epoch 1409/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0043e-04\n",
            "Epoch 1410/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0128e-04\n",
            "Epoch 1411/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0849e-04\n",
            "Epoch 1412/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0841e-04\n",
            "Epoch 1413/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0023e-04\n",
            "Epoch 1414/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9950e-04\n",
            "Epoch 1415/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9985e-04\n",
            "Epoch 1416/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9711e-04\n",
            "Epoch 1417/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0864e-04\n",
            "Epoch 1418/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0587e-04\n",
            "Epoch 1419/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0458e-04\n",
            "Epoch 1420/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0066e-04\n",
            "Epoch 1421/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0221e-04\n",
            "Epoch 1422/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0666e-04\n",
            "Epoch 1423/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0066e-04\n",
            "Epoch 1424/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0224e-04\n",
            "Epoch 1425/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1427e-04\n",
            "Epoch 1426/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9984e-04\n",
            "Epoch 1427/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9973e-04\n",
            "Epoch 1428/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9265e-04\n",
            "Epoch 1429/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0446e-04\n",
            "Epoch 1430/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0481e-04\n",
            "Epoch 1431/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0383e-04\n",
            "Epoch 1432/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0046e-04\n",
            "Epoch 1433/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9530e-04\n",
            "Epoch 1434/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1490e-04\n",
            "Epoch 1435/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1730e-04\n",
            "Epoch 1436/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.5822e-04\n",
            "Epoch 1437/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1649e-04\n",
            "Epoch 1438/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0145e-04\n",
            "Epoch 1439/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2868e-04\n",
            "Epoch 1440/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1687e-04\n",
            "Epoch 1441/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0536e-04\n",
            "Epoch 1442/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2239e-04\n",
            "Epoch 1443/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0353e-04\n",
            "Epoch 1444/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0039e-04\n",
            "Epoch 1445/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0942e-04\n",
            "Epoch 1446/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1399e-04\n",
            "Epoch 1447/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9670e-04\n",
            "Epoch 1448/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9811e-04\n",
            "Epoch 1449/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0670e-04\n",
            "Epoch 1450/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0379e-04\n",
            "Epoch 1451/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0478e-04\n",
            "Epoch 1452/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9970e-04\n",
            "Epoch 1453/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9906e-04\n",
            "Epoch 1454/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2510e-04\n",
            "Epoch 1455/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9767e-04\n",
            "Epoch 1456/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0064e-04\n",
            "Epoch 1457/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1020e-04\n",
            "Epoch 1458/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1059e-04\n",
            "Epoch 1459/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9658e-04\n",
            "Epoch 1460/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0401e-04\n",
            "Epoch 1461/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0032e-04\n",
            "Epoch 1462/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9741e-04\n",
            "Epoch 1463/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9815e-04\n",
            "Epoch 1464/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9697e-04\n",
            "Epoch 1465/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9866e-04\n",
            "Epoch 1466/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0512e-04\n",
            "Epoch 1467/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0252e-04\n",
            "Epoch 1468/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9769e-04\n",
            "Epoch 1469/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0305e-04\n",
            "Epoch 1470/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9425e-04\n",
            "Epoch 1471/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 4.9810e-04\n",
            "Epoch 1472/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.0124e-04\n",
            "Epoch 1473/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9700e-04\n",
            "Epoch 1474/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.1757e-04\n",
            "Epoch 1475/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0169e-04\n",
            "Epoch 1476/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9572e-04\n",
            "Epoch 1477/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0974e-04\n",
            "Epoch 1478/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2070e-04\n",
            "Epoch 1479/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9771e-04\n",
            "Epoch 1480/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9409e-04\n",
            "Epoch 1481/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0824e-04\n",
            "Epoch 1482/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0004e-04\n",
            "Epoch 1483/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0015e-04\n",
            "Epoch 1484/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9642e-04\n",
            "Epoch 1485/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1650e-04\n",
            "Epoch 1486/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 4.9926e-04\n",
            "Epoch 1487/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0371e-04\n",
            "Epoch 1488/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0642e-04\n",
            "Epoch 1489/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9903e-04\n",
            "Epoch 1490/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9917e-04\n",
            "Epoch 1491/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9716e-04\n",
            "Epoch 1492/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0670e-04\n",
            "Epoch 1493/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0732e-04\n",
            "Epoch 1494/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1660e-04\n",
            "Epoch 1495/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9359e-04\n",
            "Epoch 1496/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0013e-04\n",
            "Epoch 1497/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0052e-04\n",
            "Epoch 1498/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9702e-04\n",
            "Epoch 1499/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0431e-04\n",
            "Epoch 1500/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9772e-04\n",
            "Epoch 1501/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9998e-04\n",
            "Epoch 1502/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1221e-04\n",
            "Epoch 1503/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9874e-04\n",
            "Epoch 1504/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9449e-04\n",
            "Epoch 1505/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9737e-04\n",
            "Epoch 1506/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1251e-04\n",
            "Epoch 1507/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0397e-04\n",
            "Epoch 1508/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1256e-04\n",
            "Epoch 1509/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0090e-04\n",
            "Epoch 1510/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0229e-04\n",
            "Epoch 1511/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0882e-04\n",
            "Epoch 1512/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0961e-04\n",
            "Epoch 1513/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0278e-04\n",
            "Epoch 1514/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9842e-04\n",
            "Epoch 1515/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9714e-04\n",
            "Epoch 1516/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9507e-04\n",
            "Epoch 1517/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 5.0147e-04\n",
            "Epoch 1518/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1302e-04\n",
            "Epoch 1519/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1509e-04\n",
            "Epoch 1520/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0988e-04\n",
            "Epoch 1521/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0418e-04\n",
            "Epoch 1522/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9598e-04\n",
            "Epoch 1523/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0467e-04\n",
            "Epoch 1524/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2972e-04\n",
            "Epoch 1525/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1185e-04\n",
            "Epoch 1526/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1199e-04\n",
            "Epoch 1527/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9764e-04\n",
            "Epoch 1528/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9832e-04\n",
            "Epoch 1529/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0997e-04\n",
            "Epoch 1530/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0277e-04\n",
            "Epoch 1531/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9893e-04\n",
            "Epoch 1532/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0055e-04\n",
            "Epoch 1533/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0054e-04\n",
            "Epoch 1534/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9675e-04\n",
            "Epoch 1535/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0018e-04\n",
            "Epoch 1536/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0622e-04\n",
            "Epoch 1537/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9814e-04\n",
            "Epoch 1538/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0918e-04\n",
            "Epoch 1539/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1187e-04\n",
            "Epoch 1540/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2340e-04\n",
            "Epoch 1541/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0117e-04\n",
            "Epoch 1542/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0029e-04\n",
            "Epoch 1543/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0559e-04\n",
            "Epoch 1544/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0735e-04\n",
            "Epoch 1545/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1080e-04\n",
            "Epoch 1546/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0890e-04\n",
            "Epoch 1547/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0728e-04\n",
            "Epoch 1548/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9494e-04\n",
            "Epoch 1549/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0045e-04\n",
            "Epoch 1550/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9479e-04\n",
            "Epoch 1551/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0025e-04\n",
            "Epoch 1552/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0689e-04\n",
            "Epoch 1553/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1071e-04\n",
            "Epoch 1554/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0544e-04\n",
            "Epoch 1555/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9505e-04\n",
            "Epoch 1556/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1099e-04\n",
            "Epoch 1557/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0107e-04\n",
            "Epoch 1558/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9812e-04\n",
            "Epoch 1559/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9986e-04\n",
            "Epoch 1560/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9837e-04\n",
            "Epoch 1561/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0084e-04\n",
            "Epoch 1562/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9678e-04\n",
            "Epoch 1563/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9697e-04\n",
            "Epoch 1564/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0156e-04\n",
            "Epoch 1565/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1904e-04\n",
            "Epoch 1566/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0014e-04\n",
            "Epoch 1567/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0184e-04\n",
            "Epoch 1568/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0225e-04\n",
            "Epoch 1569/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0971e-04\n",
            "Epoch 1570/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0673e-04\n",
            "Epoch 1571/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1168e-04\n",
            "Epoch 1572/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0755e-04\n",
            "Epoch 1573/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0426e-04\n",
            "Epoch 1574/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0659e-04\n",
            "Epoch 1575/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1596e-04\n",
            "Epoch 1576/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0764e-04\n",
            "Epoch 1577/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9930e-04\n",
            "Epoch 1578/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0134e-04\n",
            "Epoch 1579/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0183e-04\n",
            "Epoch 1580/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2506e-04\n",
            "Epoch 1581/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0356e-04\n",
            "Epoch 1582/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0796e-04\n",
            "Epoch 1583/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0026e-04\n",
            "Epoch 1584/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9880e-04\n",
            "Epoch 1585/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0596e-04\n",
            "Epoch 1586/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0418e-04\n",
            "Epoch 1587/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0722e-04\n",
            "Epoch 1588/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0153e-04\n",
            "Epoch 1589/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9943e-04\n",
            "Epoch 1590/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9672e-04\n",
            "Epoch 1591/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0972e-04\n",
            "Epoch 1592/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0368e-04\n",
            "Epoch 1593/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1521e-04\n",
            "Epoch 1594/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1165e-04\n",
            "Epoch 1595/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9822e-04\n",
            "Epoch 1596/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1216e-04\n",
            "Epoch 1597/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9599e-04\n",
            "Epoch 1598/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9620e-04\n",
            "Epoch 1599/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0197e-04\n",
            "Epoch 1600/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0236e-04\n",
            "Epoch 1601/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9591e-04\n",
            "Epoch 1602/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0460e-04\n",
            "Epoch 1603/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0653e-04\n",
            "Epoch 1604/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0937e-04\n",
            "Epoch 1605/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9822e-04\n",
            "Epoch 1606/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0672e-04\n",
            "Epoch 1607/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0317e-04\n",
            "Epoch 1608/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0070e-04\n",
            "Epoch 1609/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0742e-04\n",
            "Epoch 1610/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0999e-04\n",
            "Epoch 1611/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0084e-04\n",
            "Epoch 1612/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9626e-04\n",
            "Epoch 1613/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0183e-04\n",
            "Epoch 1614/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9303e-04\n",
            "Epoch 1615/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9613e-04\n",
            "Epoch 1616/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9604e-04\n",
            "Epoch 1617/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0497e-04\n",
            "Epoch 1618/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0731e-04\n",
            "Epoch 1619/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1231e-04\n",
            "Epoch 1620/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9366e-04\n",
            "Epoch 1621/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9766e-04\n",
            "Epoch 1622/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0648e-04\n",
            "Epoch 1623/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0936e-04\n",
            "Epoch 1624/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1543e-04\n",
            "Epoch 1625/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9955e-04\n",
            "Epoch 1626/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0628e-04\n",
            "Epoch 1627/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1422e-04\n",
            "Epoch 1628/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1390e-04\n",
            "Epoch 1629/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0766e-04\n",
            "Epoch 1630/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9218e-04\n",
            "Epoch 1631/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0114e-04\n",
            "Epoch 1632/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9953e-04\n",
            "Epoch 1633/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0183e-04\n",
            "Epoch 1634/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0051e-04\n",
            "Epoch 1635/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2201e-04\n",
            "Epoch 1636/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1071e-04\n",
            "Epoch 1637/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9635e-04\n",
            "Epoch 1638/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1712e-04\n",
            "Epoch 1639/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1006e-04\n",
            "Epoch 1640/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9744e-04\n",
            "Epoch 1641/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2618e-04\n",
            "Epoch 1642/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1404e-04\n",
            "Epoch 1643/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.2816e-04\n",
            "Epoch 1644/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0470e-04\n",
            "Epoch 1645/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0633e-04\n",
            "Epoch 1646/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9513e-04\n",
            "Epoch 1647/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0150e-04\n",
            "Epoch 1648/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9682e-04\n",
            "Epoch 1649/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0635e-04\n",
            "Epoch 1650/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9861e-04\n",
            "Epoch 1651/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9691e-04\n",
            "Epoch 1652/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9327e-04\n",
            "Epoch 1653/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0140e-04\n",
            "Epoch 1654/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0516e-04\n",
            "Epoch 1655/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0428e-04\n",
            "Epoch 1656/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2966e-04\n",
            "Epoch 1657/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9627e-04\n",
            "Epoch 1658/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9947e-04\n",
            "Epoch 1659/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0098e-04\n",
            "Epoch 1660/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9785e-04\n",
            "Epoch 1661/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9602e-04\n",
            "Epoch 1662/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9555e-04\n",
            "Epoch 1663/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0712e-04\n",
            "Epoch 1664/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0307e-04\n",
            "Epoch 1665/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0094e-04\n",
            "Epoch 1666/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0573e-04\n",
            "Epoch 1667/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0290e-04\n",
            "Epoch 1668/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9647e-04\n",
            "Epoch 1669/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9915e-04\n",
            "Epoch 1670/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0548e-04\n",
            "Epoch 1671/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9859e-04\n",
            "Epoch 1672/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9743e-04\n",
            "Epoch 1673/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0129e-04\n",
            "Epoch 1674/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2039e-04\n",
            "Epoch 1675/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0829e-04\n",
            "Epoch 1676/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1541e-04\n",
            "Epoch 1677/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9816e-04\n",
            "Epoch 1678/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0121e-04\n",
            "Epoch 1679/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1340e-04\n",
            "Epoch 1680/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9353e-04\n",
            "Epoch 1681/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9826e-04\n",
            "Epoch 1682/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9817e-04\n",
            "Epoch 1683/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1519e-04\n",
            "Epoch 1684/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1002e-04\n",
            "Epoch 1685/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0088e-04\n",
            "Epoch 1686/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0323e-04\n",
            "Epoch 1687/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9984e-04\n",
            "Epoch 1688/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1486e-04\n",
            "Epoch 1689/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1477e-04\n",
            "Epoch 1690/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0167e-04\n",
            "Epoch 1691/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9862e-04\n",
            "Epoch 1692/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9946e-04\n",
            "Epoch 1693/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0139e-04\n",
            "Epoch 1694/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1218e-04\n",
            "Epoch 1695/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1566e-04\n",
            "Epoch 1696/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0293e-04\n",
            "Epoch 1697/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9856e-04\n",
            "Epoch 1698/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0576e-04\n",
            "Epoch 1699/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9775e-04\n",
            "Epoch 1700/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0027e-04\n",
            "Epoch 1701/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0317e-04\n",
            "Epoch 1702/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 4.9388e-04\n",
            "Epoch 1703/2000\n",
            "1566/1566 [==============================] - 0s 35us/step - loss: 4.9890e-04\n",
            "Epoch 1704/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 4.9571e-04\n",
            "Epoch 1705/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 4.9981e-04\n",
            "Epoch 1706/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9504e-04\n",
            "Epoch 1707/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9772e-04\n",
            "Epoch 1708/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0814e-04\n",
            "Epoch 1709/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9638e-04\n",
            "Epoch 1710/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0743e-04\n",
            "Epoch 1711/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0649e-04\n",
            "Epoch 1712/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0297e-04\n",
            "Epoch 1713/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9599e-04\n",
            "Epoch 1714/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2494e-04\n",
            "Epoch 1715/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9840e-04\n",
            "Epoch 1716/2000\n",
            "1566/1566 [==============================] - 0s 34us/step - loss: 4.9901e-04\n",
            "Epoch 1717/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9559e-04\n",
            "Epoch 1718/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0437e-04\n",
            "Epoch 1719/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9322e-04\n",
            "Epoch 1720/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9266e-04\n",
            "Epoch 1721/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9606e-04\n",
            "Epoch 1722/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9716e-04\n",
            "Epoch 1723/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9706e-04\n",
            "Epoch 1724/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9449e-04\n",
            "Epoch 1725/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0106e-04\n",
            "Epoch 1726/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0070e-04\n",
            "Epoch 1727/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 4.9469e-04\n",
            "Epoch 1728/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9880e-04\n",
            "Epoch 1729/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0153e-04\n",
            "Epoch 1730/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9705e-04\n",
            "Epoch 1731/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9447e-04\n",
            "Epoch 1732/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9568e-04\n",
            "Epoch 1733/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9380e-04\n",
            "Epoch 1734/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0135e-04\n",
            "Epoch 1735/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9673e-04\n",
            "Epoch 1736/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1344e-04\n",
            "Epoch 1737/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0554e-04\n",
            "Epoch 1738/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0595e-04\n",
            "Epoch 1739/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2278e-04\n",
            "Epoch 1740/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2024e-04\n",
            "Epoch 1741/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1048e-04\n",
            "Epoch 1742/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9581e-04\n",
            "Epoch 1743/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0018e-04\n",
            "Epoch 1744/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0165e-04\n",
            "Epoch 1745/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0879e-04\n",
            "Epoch 1746/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2159e-04\n",
            "Epoch 1747/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0566e-04\n",
            "Epoch 1748/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9891e-04\n",
            "Epoch 1749/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.2112e-04\n",
            "Epoch 1750/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9755e-04\n",
            "Epoch 1751/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9647e-04\n",
            "Epoch 1752/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9467e-04\n",
            "Epoch 1753/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1291e-04\n",
            "Epoch 1754/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1259e-04\n",
            "Epoch 1755/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1322e-04\n",
            "Epoch 1756/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0113e-04\n",
            "Epoch 1757/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9446e-04\n",
            "Epoch 1758/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9756e-04\n",
            "Epoch 1759/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9192e-04\n",
            "Epoch 1760/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9753e-04\n",
            "Epoch 1761/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0092e-04\n",
            "Epoch 1762/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9731e-04\n",
            "Epoch 1763/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.1327e-04\n",
            "Epoch 1764/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0032e-04\n",
            "Epoch 1765/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0787e-04\n",
            "Epoch 1766/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9888e-04\n",
            "Epoch 1767/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9713e-04\n",
            "Epoch 1768/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0612e-04\n",
            "Epoch 1769/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0820e-04\n",
            "Epoch 1770/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1824e-04\n",
            "Epoch 1771/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1455e-04\n",
            "Epoch 1772/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9708e-04\n",
            "Epoch 1773/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9365e-04\n",
            "Epoch 1774/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0365e-04\n",
            "Epoch 1775/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9883e-04\n",
            "Epoch 1776/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1879e-04\n",
            "Epoch 1777/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0703e-04\n",
            "Epoch 1778/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9739e-04\n",
            "Epoch 1779/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9828e-04\n",
            "Epoch 1780/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0539e-04\n",
            "Epoch 1781/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0350e-04\n",
            "Epoch 1782/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9564e-04\n",
            "Epoch 1783/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9536e-04\n",
            "Epoch 1784/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9502e-04\n",
            "Epoch 1785/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9952e-04\n",
            "Epoch 1786/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9737e-04\n",
            "Epoch 1787/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9579e-04\n",
            "Epoch 1788/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9609e-04\n",
            "Epoch 1789/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0092e-04\n",
            "Epoch 1790/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0856e-04\n",
            "Epoch 1791/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0187e-04\n",
            "Epoch 1792/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9524e-04\n",
            "Epoch 1793/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9546e-04\n",
            "Epoch 1794/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9335e-04\n",
            "Epoch 1795/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9495e-04\n",
            "Epoch 1796/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9676e-04\n",
            "Epoch 1797/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2329e-04\n",
            "Epoch 1798/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0408e-04\n",
            "Epoch 1799/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9665e-04\n",
            "Epoch 1800/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0051e-04\n",
            "Epoch 1801/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9878e-04\n",
            "Epoch 1802/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0303e-04\n",
            "Epoch 1803/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9974e-04\n",
            "Epoch 1804/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0996e-04\n",
            "Epoch 1805/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9952e-04\n",
            "Epoch 1806/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0980e-04\n",
            "Epoch 1807/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0148e-04\n",
            "Epoch 1808/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9956e-04\n",
            "Epoch 1809/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9763e-04\n",
            "Epoch 1810/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0440e-04\n",
            "Epoch 1811/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1307e-04\n",
            "Epoch 1812/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9776e-04\n",
            "Epoch 1813/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9579e-04\n",
            "Epoch 1814/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9994e-04\n",
            "Epoch 1815/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0045e-04\n",
            "Epoch 1816/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 5.0483e-04\n",
            "Epoch 1817/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1631e-04\n",
            "Epoch 1818/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1887e-04\n",
            "Epoch 1819/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0177e-04\n",
            "Epoch 1820/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0188e-04\n",
            "Epoch 1821/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9897e-04\n",
            "Epoch 1822/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0302e-04\n",
            "Epoch 1823/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9855e-04\n",
            "Epoch 1824/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9634e-04\n",
            "Epoch 1825/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0119e-04\n",
            "Epoch 1826/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1720e-04\n",
            "Epoch 1827/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1057e-04\n",
            "Epoch 1828/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0851e-04\n",
            "Epoch 1829/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0784e-04\n",
            "Epoch 1830/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1900e-04\n",
            "Epoch 1831/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.3086e-04\n",
            "Epoch 1832/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1070e-04\n",
            "Epoch 1833/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0737e-04\n",
            "Epoch 1834/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0213e-04\n",
            "Epoch 1835/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0839e-04\n",
            "Epoch 1836/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9616e-04\n",
            "Epoch 1837/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9666e-04\n",
            "Epoch 1838/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0152e-04\n",
            "Epoch 1839/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0967e-04\n",
            "Epoch 1840/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1108e-04\n",
            "Epoch 1841/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9743e-04\n",
            "Epoch 1842/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0476e-04\n",
            "Epoch 1843/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0383e-04\n",
            "Epoch 1844/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9980e-04\n",
            "Epoch 1845/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9431e-04\n",
            "Epoch 1846/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0789e-04\n",
            "Epoch 1847/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1424e-04\n",
            "Epoch 1848/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1850e-04\n",
            "Epoch 1849/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0420e-04\n",
            "Epoch 1850/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9777e-04\n",
            "Epoch 1851/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9693e-04\n",
            "Epoch 1852/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1095e-04\n",
            "Epoch 1853/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0494e-04\n",
            "Epoch 1854/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9884e-04\n",
            "Epoch 1855/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9890e-04\n",
            "Epoch 1856/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9751e-04\n",
            "Epoch 1857/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1127e-04\n",
            "Epoch 1858/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0721e-04\n",
            "Epoch 1859/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0744e-04\n",
            "Epoch 1860/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0882e-04\n",
            "Epoch 1861/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9392e-04\n",
            "Epoch 1862/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9842e-04\n",
            "Epoch 1863/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0590e-04\n",
            "Epoch 1864/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1321e-04\n",
            "Epoch 1865/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9524e-04\n",
            "Epoch 1866/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0740e-04\n",
            "Epoch 1867/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0012e-04\n",
            "Epoch 1868/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0467e-04\n",
            "Epoch 1869/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9554e-04\n",
            "Epoch 1870/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9578e-04\n",
            "Epoch 1871/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0225e-04\n",
            "Epoch 1872/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1533e-04\n",
            "Epoch 1873/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0496e-04\n",
            "Epoch 1874/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9605e-04\n",
            "Epoch 1875/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9764e-04\n",
            "Epoch 1876/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9844e-04\n",
            "Epoch 1877/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9266e-04\n",
            "Epoch 1878/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9838e-04\n",
            "Epoch 1879/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9878e-04\n",
            "Epoch 1880/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0573e-04\n",
            "Epoch 1881/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9495e-04\n",
            "Epoch 1882/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9989e-04\n",
            "Epoch 1883/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0115e-04\n",
            "Epoch 1884/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2168e-04\n",
            "Epoch 1885/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.2245e-04\n",
            "Epoch 1886/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9351e-04\n",
            "Epoch 1887/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0323e-04\n",
            "Epoch 1888/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0190e-04\n",
            "Epoch 1889/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9831e-04\n",
            "Epoch 1890/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0130e-04\n",
            "Epoch 1891/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0105e-04\n",
            "Epoch 1892/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0891e-04\n",
            "Epoch 1893/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0580e-04\n",
            "Epoch 1894/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9519e-04\n",
            "Epoch 1895/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9561e-04\n",
            "Epoch 1896/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0039e-04\n",
            "Epoch 1897/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9994e-04\n",
            "Epoch 1898/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0539e-04\n",
            "Epoch 1899/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9971e-04\n",
            "Epoch 1900/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9688e-04\n",
            "Epoch 1901/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 4.9758e-04\n",
            "Epoch 1902/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9356e-04\n",
            "Epoch 1903/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9247e-04\n",
            "Epoch 1904/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9831e-04\n",
            "Epoch 1905/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2750e-04\n",
            "Epoch 1906/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2693e-04\n",
            "Epoch 1907/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0084e-04\n",
            "Epoch 1908/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0165e-04\n",
            "Epoch 1909/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 5.0612e-04\n",
            "Epoch 1910/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 4.9916e-04\n",
            "Epoch 1911/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9466e-04\n",
            "Epoch 1912/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.1861e-04\n",
            "Epoch 1913/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0418e-04\n",
            "Epoch 1914/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9640e-04\n",
            "Epoch 1915/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9318e-04\n",
            "Epoch 1916/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9769e-04\n",
            "Epoch 1917/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 4.9274e-04\n",
            "Epoch 1918/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9457e-04\n",
            "Epoch 1919/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9543e-04\n",
            "Epoch 1920/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.5690e-04\n",
            "Epoch 1921/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0568e-04\n",
            "Epoch 1922/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0659e-04\n",
            "Epoch 1923/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0453e-04\n",
            "Epoch 1924/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9547e-04\n",
            "Epoch 1925/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9430e-04\n",
            "Epoch 1926/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9680e-04\n",
            "Epoch 1927/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1532e-04\n",
            "Epoch 1928/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1613e-04\n",
            "Epoch 1929/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0744e-04\n",
            "Epoch 1930/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0927e-04\n",
            "Epoch 1931/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0567e-04\n",
            "Epoch 1932/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0296e-04\n",
            "Epoch 1933/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9598e-04\n",
            "Epoch 1934/2000\n",
            "1566/1566 [==============================] - 0s 41us/step - loss: 5.0121e-04\n",
            "Epoch 1935/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0052e-04\n",
            "Epoch 1936/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0093e-04\n",
            "Epoch 1937/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 4.9735e-04\n",
            "Epoch 1938/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0753e-04\n",
            "Epoch 1939/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1538e-04\n",
            "Epoch 1940/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.2289e-04\n",
            "Epoch 1941/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.1845e-04\n",
            "Epoch 1942/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.2921e-04\n",
            "Epoch 1943/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1525e-04\n",
            "Epoch 1944/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9553e-04\n",
            "Epoch 1945/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9502e-04\n",
            "Epoch 1946/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.1036e-04\n",
            "Epoch 1947/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1712e-04\n",
            "Epoch 1948/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9445e-04\n",
            "Epoch 1949/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9305e-04\n",
            "Epoch 1950/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0631e-04\n",
            "Epoch 1951/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0181e-04\n",
            "Epoch 1952/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9390e-04\n",
            "Epoch 1953/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9670e-04\n",
            "Epoch 1954/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9172e-04\n",
            "Epoch 1955/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9557e-04\n",
            "Epoch 1956/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9577e-04\n",
            "Epoch 1957/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0212e-04\n",
            "Epoch 1958/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9261e-04\n",
            "Epoch 1959/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0327e-04\n",
            "Epoch 1960/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0561e-04\n",
            "Epoch 1961/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0913e-04\n",
            "Epoch 1962/2000\n",
            "1566/1566 [==============================] - 0s 33us/step - loss: 4.9273e-04\n",
            "Epoch 1963/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9648e-04\n",
            "Epoch 1964/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9619e-04\n",
            "Epoch 1965/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9562e-04\n",
            "Epoch 1966/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0620e-04\n",
            "Epoch 1967/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0901e-04\n",
            "Epoch 1968/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0532e-04\n",
            "Epoch 1969/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9479e-04\n",
            "Epoch 1970/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0056e-04\n",
            "Epoch 1971/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 5.0890e-04\n",
            "Epoch 1972/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0119e-04\n",
            "Epoch 1973/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9833e-04\n",
            "Epoch 1974/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0454e-04\n",
            "Epoch 1975/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9973e-04\n",
            "Epoch 1976/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9226e-04\n",
            "Epoch 1977/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9399e-04\n",
            "Epoch 1978/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0512e-04\n",
            "Epoch 1979/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.1014e-04\n",
            "Epoch 1980/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 4.9175e-04\n",
            "Epoch 1981/2000\n",
            "1566/1566 [==============================] - 0s 26us/step - loss: 5.0594e-04\n",
            "Epoch 1982/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9535e-04\n",
            "Epoch 1983/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9636e-04\n",
            "Epoch 1984/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0357e-04\n",
            "Epoch 1985/2000\n",
            "1566/1566 [==============================] - 0s 32us/step - loss: 4.9884e-04\n",
            "Epoch 1986/2000\n",
            "1566/1566 [==============================] - 0s 31us/step - loss: 5.0976e-04\n",
            "Epoch 1987/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9865e-04\n",
            "Epoch 1988/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 5.0247e-04\n",
            "Epoch 1989/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9443e-04\n",
            "Epoch 1990/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9361e-04\n",
            "Epoch 1991/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 5.0121e-04\n",
            "Epoch 1992/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9706e-04\n",
            "Epoch 1993/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9329e-04\n",
            "Epoch 1994/2000\n",
            "1566/1566 [==============================] - 0s 30us/step - loss: 4.9605e-04\n",
            "Epoch 1995/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0109e-04\n",
            "Epoch 1996/2000\n",
            "1566/1566 [==============================] - 0s 29us/step - loss: 4.9294e-04\n",
            "Epoch 1997/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0730e-04\n",
            "Epoch 1998/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 5.0080e-04\n",
            "Epoch 1999/2000\n",
            "1566/1566 [==============================] - 0s 27us/step - loss: 4.9416e-04\n",
            "Epoch 2000/2000\n",
            "1566/1566 [==============================] - 0s 28us/step - loss: 4.9477e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ff1647a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-W-Lh2jhGOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7290c754-1c0d-47a7-879c-2adc81523841"
      },
      "source": [
        "print(np.tanh(reg_model.layers[0].get_weights()[3]))\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6268091]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE90OgzpcWB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "25f3f206-7fe0-41da-8dba-6e5a4cbd85d4"
      },
      "source": [
        "alpha_rnn_pred_train = reg_model.predict(x_train_reg, verbose=1)\n",
        "alpha_rnn_pred_test = reg_model.predict(x_test_reg, verbose=1)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1566/1566 [==============================] - 1s 347us/step\n",
            "384/384 [==============================] - 0s 37us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaT2m6A7erEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "1361dd6b-2dbb-4adc-eb79-24ac3d00b145"
      },
      "source": [
        "fig = plt.figure(figsize=(12,7))\n",
        "test_line_real = plt.plot(df_test.index[n_steps:], df_test[use_feature][n_steps:], color=\"orange\", label=\"Observed (Testing)\")\n",
        "test_line_pred = plt.plot(df_test.index[n_steps:], alpha_rnn_pred_test[:, 0], color=\"red\", label=\"RNN Predict (Testing)\")\n",
        "plt.legend(loc=\"best\", fontsize=12)\n",
        "plt.title('Observed vs Model (Testing)', fontsize=16)\n",
        "plt.xlabel('Time', fontsize=20)\n",
        "plt.ylabel('Y', fontsize=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAAHHCAYAAAD3dE1gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nASkhFxEREREJSAm5iIiIiEhA/w/3oikEQrNdpQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxS4AYIZf57S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RNN_model(n_units=10, l1_reg=0):\n",
        "    reg_model = Sequential()\n",
        "    reg_model.add(SimpleRNN(n_units, activation='tanh', input_shape=(x_train_reg.shape[1], x_train_reg.shape[-1]), unroll=True))\n",
        "    reg_model.add(Dense(1, kernel_initializer='normal', kernel_regularizer=l1(l1_reg)))\n",
        "    #reg_model.add(Dropout(0.2))\n",
        "    reg_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return reg_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6MLiMOyf-tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model=RNN_model(hidden_units, l1_reg)\n",
        "rnn_model.fit(x_train_reg,y_train_reg,epochs=2000, batch_size=100, callbacks=[es])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIXAHIj2i_Qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT3ucd9Fid57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1d305437-b4aa-422c-9dee-f00a3c61038c"
      },
      "source": [
        "rnn_pred_train = rnn_model.predict(x_train_reg, verbose=1)\n",
        "rnn_pred_test = rnn_model.predict(x_test_reg, verbose=1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1566/1566 [==============================] - 0s 33us/step\n",
            "384/384 [==============================] - 0s 38us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxcTtqC7iixP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "0c132166-ccdc-4d79-a3b8-eba46e51b9ec"
      },
      "source": [
        "fig = plt.figure(figsize=(12,7))\n",
        "test_line_real = plt.plot(df_test.index[n_steps:], df_test[use_feature][n_steps:], color=\"black\", label=\"Observed (Testing)\")\n",
        "test_line_pred = plt.plot(df_test.index[n_steps:], alpha_rnn_pred_test[:, 0], color=\"red\", label=\"alpha RNN Predict (Testing)\")\n",
        "plt.plot(df_test.index[n_steps:], rnn_pred_test[:, 0], color=\"blue\", label=\"RNN Predict (Testing)\")\n",
        "\n",
        "plt.legend(loc=\"best\", fontsize=12)\n",
        "plt.title('Observed vs Model (Testing)', fontsize=16)\n",
        "plt.xlabel('Time', fontsize=20)\n",
        "plt.ylabel('Y', fontsize=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuQAAAHHCAYAAAD3dE1gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCSPlJCLiIiIiOSREnIRERERkTz6/62Xq3t+RszOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}